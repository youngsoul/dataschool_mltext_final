{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSchool - Machine Learning with Text and Python:  \n",
    "\n",
    "### Week 6 Self Imposed Homework\n",
    "\n",
    "I am going to use the Kaggle competition that inspired me to sign up for this course.  Using what I have learned in the Machine Learning with Text course, I will attempt to beat the scores on the leader board.\n",
    "\n",
    "The Kaggle competition is:\n",
    "\n",
    "![SA Image](sa_emotions_picture.png) \n",
    "\n",
    "### [Sentiment Analysis: Emotion in Text.](https://www.kaggle.com/c/sa-emotions)\n",
    "\n",
    "*Identify emotion in text using sentiment analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from stemming.porter2 import stem\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sentiment_analysis.transformers import RemoveEllipseTransformer, RemoveHtmlEncodedTransformer, RemoveNumbersTransformer, RemoveSpecialCharactersTransformer, RemoveUsernameTransformer, RemoveUrlsTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import TransformerMixin\n",
    "import re\n",
    "import nltk.stem\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from nltk.sentiment.util import mark_negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# allow plots to appear in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the training data\n",
    "training_data = pd.read_csv('../data/kaggle/sa-emotions/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the shape of the data.  Kaggle stated that the training data consisted of 30000 rows and 2 columns\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    object\n",
       "content      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update the pd option to increase the column width so we can see more of the text\n",
    "pd.set_option('max_colwidth',200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@Sageey My public talk in July got canceled and I don't know why.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Epic ocd moment? I deleted my sims file that i spent hours building just because i set his favorite food wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>worry</td>\n",
       "      <td>[BBC] Malaria parasites becoming resistant to drugs  http://trunc.it/9yn5 ~ this is really not good as Malaria affects so many people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>my to do list is bananas, before i leave for Europe BOOOO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>darn it. I did it again.!  keep forgetting that darn &amp;quot;D&amp;quot; for DM's.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@chelsea_playboy R.I.P curls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@Jeanise  I was going to say let's go to lunch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>argh! why why why</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@vronmcintyre I want an espresso machine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>love</td>\n",
       "      <td>@Crazy_Cindy  BIG HUGGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>worry</td>\n",
       "      <td>is wondering y Mother Nature is making my life miserable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>happiness</td>\n",
       "      <td>Just got my paycheck... April bonus can b deposited 2day the rest, gotta wait til Mon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>worry</td>\n",
       "      <td>I don't feel good.  .My throat hurts!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@QuindaS  your right.... How was your trip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@RealJessicaAlba Is it true there won't be any Fantastic 4 sequels?  I wished they introduced a Franklin Richards character... will they?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>hate</td>\n",
       "      <td>I hate waiting in lines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@dunnybrasco Im home, phone died thou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>worry</td>\n",
       "      <td>is gonna be mad hungry when I get home. Forgot my money...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>really tired. and have to work the whole day tomorrow, the thought of it depresses me.  uncoooool....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>empty</td>\n",
       "      <td>Thanks for pointing out the crucial problems @thakkar. Both of them have been taken care of  (cc: @Netra)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@KatieAlender ooh which two books did you buy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22000</th>\n",
       "      <td>empty</td>\n",
       "      <td>@greyeyesgabriel You are clearly very busy  Take care of yourself, and I am sure you will be fine; takes one to know one ;)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23000</th>\n",
       "      <td>relief</td>\n",
       "      <td>is back in fine old melbourne town....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24000</th>\n",
       "      <td>hate</td>\n",
       "      <td>@girltrumpet yeahh  idk if i like owen anymore though... i kinda lost respect for him in an episode i recorded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>fun</td>\n",
       "      <td>'Look at the tadpole'... 'No! ... Look at me!!!' ... Foolish dog  http://yfrog.com/05ixbj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26000</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@azkikah the idiom?? doesn't ring a bell eh? hahaha. y'are really thinking of food?! nope. actually in the bathroom. teehee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27000</th>\n",
       "      <td>empty</td>\n",
       "      <td>@sugarrae i thought you would win!  Fabulously40 have some bots on her side?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@AnnebrittB slaying dragons &amp;amp; rescue innocents, this could be a good life movie   Make sure to take a camara and film!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@jareason left a comment on your blog post</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "0          empty   \n",
       "1000       worry   \n",
       "2000     sadness   \n",
       "3000       worry   \n",
       "4000     neutral   \n",
       "5000     sadness   \n",
       "6000     neutral   \n",
       "7000     neutral   \n",
       "8000     sadness   \n",
       "9000       worry   \n",
       "10000       love   \n",
       "11000      worry   \n",
       "12000  happiness   \n",
       "13000      worry   \n",
       "14000    neutral   \n",
       "15000   surprise   \n",
       "16000       hate   \n",
       "17000      worry   \n",
       "18000      worry   \n",
       "19000    sadness   \n",
       "20000      empty   \n",
       "21000    neutral   \n",
       "22000      empty   \n",
       "23000     relief   \n",
       "24000       hate   \n",
       "25000        fun   \n",
       "26000   surprise   \n",
       "27000      empty   \n",
       "28000      worry   \n",
       "29000    neutral   \n",
       "\n",
       "                                                                                                                                         content  \n",
       "0                                                   @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[  \n",
       "1000                                                                           @Sageey My public talk in July got canceled and I don't know why.  \n",
       "2000                              Epic ocd moment? I deleted my sims file that i spent hours building just because i set his favorite food wrong  \n",
       "3000       [BBC] Malaria parasites becoming resistant to drugs  http://trunc.it/9yn5 ~ this is really not good as Malaria affects so many people  \n",
       "4000                                                                                   my to do list is bananas, before i leave for Europe BOOOO  \n",
       "5000                                                            darn it. I did it again.!  keep forgetting that darn &quot;D&quot; for DM's.....  \n",
       "6000                                                                                                                @chelsea_playboy R.I.P curls  \n",
       "7000                                                                                           @Jeanise  I was going to say let's go to lunch...  \n",
       "8000                                                                                                                           argh! why why why  \n",
       "9000                                                                                                    @vronmcintyre I want an espresso machine  \n",
       "10000                                                                                                                    @Crazy_Cindy  BIG HUGGS  \n",
       "11000                                                                                   is wondering y Mother Nature is making my life miserable  \n",
       "12000                                                     Just got my paycheck... April bonus can b deposited 2day the rest, gotta wait til Mon.  \n",
       "13000                                                                                                   I don't feel good.  .My throat hurts!!!!  \n",
       "14000                                                                                                 @QuindaS  your right.... How was your trip  \n",
       "15000  @RealJessicaAlba Is it true there won't be any Fantastic 4 sequels?  I wished they introduced a Franklin Richards character... will they?  \n",
       "16000                                                                                                                    I hate waiting in lines  \n",
       "17000                                                                                                      @dunnybrasco Im home, phone died thou  \n",
       "18000                                                                                 is gonna be mad hungry when I get home. Forgot my money...  \n",
       "19000                                      really tired. and have to work the whole day tomorrow, the thought of it depresses me.  uncoooool....  \n",
       "20000                                  Thanks for pointing out the crucial problems @thakkar. Both of them have been taken care of  (cc: @Netra)  \n",
       "21000                                                                                             @KatieAlender ooh which two books did you buy?  \n",
       "22000                @greyeyesgabriel You are clearly very busy  Take care of yourself, and I am sure you will be fine; takes one to know one ;)  \n",
       "23000                                                                                                     is back in fine old melbourne town....  \n",
       "24000                          @girltrumpet yeahh  idk if i like owen anymore though... i kinda lost respect for him in an episode i recorded...  \n",
       "25000                                                  'Look at the tadpole'... 'No! ... Look at me!!!' ... Foolish dog  http://yfrog.com/05ixbj  \n",
       "26000                @azkikah the idiom?? doesn't ring a bell eh? hahaha. y'are really thinking of food?! nope. actually in the bathroom. teehee  \n",
       "27000                                                               @sugarrae i thought you would win!  Fabulously40 have some bots on her side?  \n",
       "28000              @AnnebrittB slaying dragons &amp; rescue innocents, this could be a good life movie   Make sure to take a camara and film!!!!  \n",
       "29000                                                                                                 @jareason left a comment on your blog post  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at a small sample of the data by looking at every 1000th\n",
    "training_data[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "content      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null or NaN values in the columns\n",
    "training_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worry         7433\n",
       "neutral       6340\n",
       "sadness       4828\n",
       "happiness     2986\n",
       "love          2068\n",
       "surprise      1613\n",
       "hate          1187\n",
       "fun           1088\n",
       "relief        1021\n",
       "empty          659\n",
       "enthusiasm     522\n",
       "boredom        157\n",
       "anger           98\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the sentiment distribution\n",
    "training_data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worry         0.247767\n",
       "neutral       0.211333\n",
       "sadness       0.160933\n",
       "happiness     0.099533\n",
       "love          0.068933\n",
       "surprise      0.053767\n",
       "hate          0.039567\n",
       "fun           0.036267\n",
       "relief        0.034033\n",
       "empty         0.021967\n",
       "enthusiasm    0.017400\n",
       "boredom       0.005233\n",
       "anger         0.003267\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the percent distribution of sentiment\n",
    "training_data.sentiment.value_counts()/training_data.sentiment.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Some of sentiments have a very low percent of the total count.  It is expected that it will be difficult to accurately predict anger and boredom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the sentiment outcomes as a number using the LabelEncoder\n",
    "# would like to create a column, e.g. sentiment_num, which is a numeric representation of the sentiment.\n",
    "# this will have to also be applied to any test data.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# fit the label encoder with the unique set of sentiments in the training data.\n",
    "label_encoder.fit(training_data.sentiment.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger',\n",
       " 'boredom',\n",
       " 'empty',\n",
       " 'enthusiasm',\n",
       " 'fun',\n",
       " 'happiness',\n",
       " 'hate',\n",
       " 'love',\n",
       " 'neutral',\n",
       " 'relief',\n",
       " 'sadness',\n",
       " 'surprise',\n",
       " 'worry']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print out what classes were discovered\n",
    "list(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# planning ahead, create a function to create features in a data set that we will have to create in \n",
    "# both the training and testing data\n",
    "def make_features(df, sentiment_num_encoder):\n",
    "    training_data['sentiment_num'] = training_data.sentiment.apply(lambda x: label_encoder.transform([x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@Sageey My public talk in July got canceled and I don't know why.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Epic ocd moment? I deleted my sims file that i spent hours building just because i set his favorite food wrong</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>worry</td>\n",
       "      <td>[BBC] Malaria parasites becoming resistant to drugs  http://trunc.it/9yn5 ~ this is really not good as Malaria affects so many people</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>my to do list is bananas, before i leave for Europe BOOOO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>darn it. I did it again.!  keep forgetting that darn &amp;quot;D&amp;quot; for DM's.....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@chelsea_playboy R.I.P curls</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@Jeanise  I was going to say let's go to lunch...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>argh! why why why</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@vronmcintyre I want an espresso machine</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>love</td>\n",
       "      <td>@Crazy_Cindy  BIG HUGGS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>worry</td>\n",
       "      <td>is wondering y Mother Nature is making my life miserable</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>happiness</td>\n",
       "      <td>Just got my paycheck... April bonus can b deposited 2day the rest, gotta wait til Mon.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>worry</td>\n",
       "      <td>I don't feel good.  .My throat hurts!!!!</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@QuindaS  your right.... How was your trip</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@RealJessicaAlba Is it true there won't be any Fantastic 4 sequels?  I wished they introduced a Franklin Richards character... will they?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>hate</td>\n",
       "      <td>I hate waiting in lines</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@dunnybrasco Im home, phone died thou</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>worry</td>\n",
       "      <td>is gonna be mad hungry when I get home. Forgot my money...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>really tired. and have to work the whole day tomorrow, the thought of it depresses me.  uncoooool....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>empty</td>\n",
       "      <td>Thanks for pointing out the crucial problems @thakkar. Both of them have been taken care of  (cc: @Netra)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@KatieAlender ooh which two books did you buy?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22000</th>\n",
       "      <td>empty</td>\n",
       "      <td>@greyeyesgabriel You are clearly very busy  Take care of yourself, and I am sure you will be fine; takes one to know one ;)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23000</th>\n",
       "      <td>relief</td>\n",
       "      <td>is back in fine old melbourne town....</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24000</th>\n",
       "      <td>hate</td>\n",
       "      <td>@girltrumpet yeahh  idk if i like owen anymore though... i kinda lost respect for him in an episode i recorded...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>fun</td>\n",
       "      <td>'Look at the tadpole'... 'No! ... Look at me!!!' ... Foolish dog  http://yfrog.com/05ixbj</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26000</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@azkikah the idiom?? doesn't ring a bell eh? hahaha. y'are really thinking of food?! nope. actually in the bathroom. teehee</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27000</th>\n",
       "      <td>empty</td>\n",
       "      <td>@sugarrae i thought you would win!  Fabulously40 have some bots on her side?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@AnnebrittB slaying dragons &amp;amp; rescue innocents, this could be a good life movie   Make sure to take a camara and film!!!!</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@jareason left a comment on your blog post</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "0          empty   \n",
       "1000       worry   \n",
       "2000     sadness   \n",
       "3000       worry   \n",
       "4000     neutral   \n",
       "5000     sadness   \n",
       "6000     neutral   \n",
       "7000     neutral   \n",
       "8000     sadness   \n",
       "9000       worry   \n",
       "10000       love   \n",
       "11000      worry   \n",
       "12000  happiness   \n",
       "13000      worry   \n",
       "14000    neutral   \n",
       "15000   surprise   \n",
       "16000       hate   \n",
       "17000      worry   \n",
       "18000      worry   \n",
       "19000    sadness   \n",
       "20000      empty   \n",
       "21000    neutral   \n",
       "22000      empty   \n",
       "23000     relief   \n",
       "24000       hate   \n",
       "25000        fun   \n",
       "26000   surprise   \n",
       "27000      empty   \n",
       "28000      worry   \n",
       "29000    neutral   \n",
       "\n",
       "                                                                                                                                         content  \\\n",
       "0                                                   @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1000                                                                           @Sageey My public talk in July got canceled and I don't know why.   \n",
       "2000                              Epic ocd moment? I deleted my sims file that i spent hours building just because i set his favorite food wrong   \n",
       "3000       [BBC] Malaria parasites becoming resistant to drugs  http://trunc.it/9yn5 ~ this is really not good as Malaria affects so many people   \n",
       "4000                                                                                   my to do list is bananas, before i leave for Europe BOOOO   \n",
       "5000                                                            darn it. I did it again.!  keep forgetting that darn &quot;D&quot; for DM's.....   \n",
       "6000                                                                                                                @chelsea_playboy R.I.P curls   \n",
       "7000                                                                                           @Jeanise  I was going to say let's go to lunch...   \n",
       "8000                                                                                                                           argh! why why why   \n",
       "9000                                                                                                    @vronmcintyre I want an espresso machine   \n",
       "10000                                                                                                                    @Crazy_Cindy  BIG HUGGS   \n",
       "11000                                                                                   is wondering y Mother Nature is making my life miserable   \n",
       "12000                                                     Just got my paycheck... April bonus can b deposited 2day the rest, gotta wait til Mon.   \n",
       "13000                                                                                                   I don't feel good.  .My throat hurts!!!!   \n",
       "14000                                                                                                 @QuindaS  your right.... How was your trip   \n",
       "15000  @RealJessicaAlba Is it true there won't be any Fantastic 4 sequels?  I wished they introduced a Franklin Richards character... will they?   \n",
       "16000                                                                                                                    I hate waiting in lines   \n",
       "17000                                                                                                      @dunnybrasco Im home, phone died thou   \n",
       "18000                                                                                 is gonna be mad hungry when I get home. Forgot my money...   \n",
       "19000                                      really tired. and have to work the whole day tomorrow, the thought of it depresses me.  uncoooool....   \n",
       "20000                                  Thanks for pointing out the crucial problems @thakkar. Both of them have been taken care of  (cc: @Netra)   \n",
       "21000                                                                                             @KatieAlender ooh which two books did you buy?   \n",
       "22000                @greyeyesgabriel You are clearly very busy  Take care of yourself, and I am sure you will be fine; takes one to know one ;)   \n",
       "23000                                                                                                     is back in fine old melbourne town....   \n",
       "24000                          @girltrumpet yeahh  idk if i like owen anymore though... i kinda lost respect for him in an episode i recorded...   \n",
       "25000                                                  'Look at the tadpole'... 'No! ... Look at me!!!' ... Foolish dog  http://yfrog.com/05ixbj   \n",
       "26000                @azkikah the idiom?? doesn't ring a bell eh? hahaha. y'are really thinking of food?! nope. actually in the bathroom. teehee   \n",
       "27000                                                               @sugarrae i thought you would win!  Fabulously40 have some bots on her side?   \n",
       "28000              @AnnebrittB slaying dragons &amp; rescue innocents, this could be a good life movie   Make sure to take a camara and film!!!!   \n",
       "29000                                                                                                 @jareason left a comment on your blog post   \n",
       "\n",
       "       sentiment_num  \n",
       "0                  2  \n",
       "1000              12  \n",
       "2000              10  \n",
       "3000              12  \n",
       "4000               8  \n",
       "5000              10  \n",
       "6000               8  \n",
       "7000               8  \n",
       "8000              10  \n",
       "9000              12  \n",
       "10000              7  \n",
       "11000             12  \n",
       "12000              5  \n",
       "13000             12  \n",
       "14000              8  \n",
       "15000             11  \n",
       "16000              6  \n",
       "17000             12  \n",
       "18000             12  \n",
       "19000             10  \n",
       "20000              2  \n",
       "21000              8  \n",
       "22000              2  \n",
       "23000              9  \n",
       "24000              6  \n",
       "25000              4  \n",
       "26000             11  \n",
       "27000              2  \n",
       "28000             12  \n",
       "29000              8  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_features(training_data, sentiment_num_encoder=label_encoder)\n",
    "training_data[::1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Line DataFrame\n",
    "\n",
    "The dataset is now minimally ready to investigate further.\n",
    "\n",
    "The next steps are Data Preprocessing to cleanse the data, and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Look at the data and see if we can/should clean the content before we attempt to engineer features and\n",
    "\n",
    "create tokens.\n",
    "\n",
    "For example, there is a very good chance that user names like '@Crazy_Cindy' has no relationship to emotion and is likely a good candidate to remove from the content before vectorization.\n",
    "\n",
    "To verify this - we will create a baseline and compare against the base.  For the baseline a generic CountVectorizer will be used with a MultinomialNB model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# baseline pipeline.\n",
    "baseline_pipeline = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the X and y variables\n",
    "X = training_data.content\n",
    "y = training_data.sentiment_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285673524552\n"
     ]
    }
   ],
   "source": [
    "# cross-validate the entire pipeline\n",
    "baseline_accuracy = cross_val_score(baseline_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38892\n"
     ]
    }
   ],
   "source": [
    "# look at the baseline number of features\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X)\n",
    "baseline_number_of_features = len(vect.get_feature_names())\n",
    "print(baseline_number_of_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Transformers.\n",
    "\n",
    "This section will contain a number of transformers that will be applied as part of a preprocessing pipeline.  Each custom transformer inherits from TransformerMixin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_transformer(transformer, data):\n",
    "    \"\"\"\n",
    "    Assumes:\n",
    "    1) training_data variable is available\n",
    "    2) baseline_pipeline variable is available\n",
    "    3) baseline_number_of_features variable is available\n",
    "    4) baseline_accuracy variable is available\n",
    "    \"\"\"\n",
    "    new_content = transformer.transform(data)\n",
    "    # Define new X and y variables\n",
    "    X = new_content\n",
    "    y = training_data.sentiment_num\n",
    "    # cross-validate the entire pipeline\n",
    "    cv_score = cross_val_score(baseline_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "    vect = CountVectorizer()\n",
    "    vect.fit(X)\n",
    "    num_feats = len(vect.get_feature_names())\n",
    "    diff = num_feats - baseline_number_of_features\n",
    "    accuracy_diff = cv_score - baseline_accuracy\n",
    "    print(\"Accuracy: {0} Accuracy Diff: {1}\\nTransformed: {2} Baseline: {3} Feature Diff: {4}\".format(cv_score, accuracy_diff, num_feats, baseline_number_of_features, diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### A transformer to remove username "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RemoveUsernameTransformer(TransformerMixin):\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_data(data_series):\n",
    "        \"\"\"\n",
    "        inspired from:\n",
    "        https://raw.githubusercontent.com/youngsoul/ml-twitter-sentiment-analysis/develop/cleanup.py\n",
    "        :param data_series:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # remove user name\n",
    "        regex = re.compile(r\"@[^\\s]+[\\s]?\")\n",
    "        data_series.replace(regex, \"\", inplace=True)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: Series, aka column of data.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        RemoveUsernameTransformer._preprocess_data(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2907763836290118 Accuracy Diff: 0.005102859076697719\n",
      "Transformed: 26729 Baseline: 38892 Feature Diff: -12163\n"
     ]
    }
   ],
   "source": [
    "# Remove the user name, save the series in a new series and see if it helped the model\n",
    "ru = RemoveUsernameTransformer()\n",
    "test_transformer(ru, training_data.content.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since the accuracy is a slight improvement, 0.285 vs 0.290, we will keep the remove username transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remove ellipse transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RemoveEllipseTransformer(TransformerMixin):\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_data(data_series):\n",
    "        \"\"\"\n",
    "        inspired from:\n",
    "        https://raw.githubusercontent.com/youngsoul/ml-twitter-sentiment-analysis/develop/cleanup.py\n",
    "        :param data_series:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # remove ..., ...., ..... with space\n",
    "        for remove in map(lambda r: re.compile(r), [\"\\.\\.\\.\\.\\.\", \"\\.\\.\\.\\.\", \"\\.\\.\\.\"]):\n",
    "            data_series.replace(remove, \" \", inplace=True)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: Series, aka column of data.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        RemoveEllipseTransformer._preprocess_data(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2856735245523141 Accuracy Diff: 0.0\n",
      "Transformed: 38892 Baseline: 38892 Feature Diff: 0\n"
     ]
    }
   ],
   "source": [
    "# Remove the ellipse, save the series in a new series and see if it helped the model\n",
    "ru = RemoveEllipseTransformer()\n",
    "test_transformer(ru, training_data.content.copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since there is no improvement, and the feature count is the same,  It is assumed that CountVectorizer must be removing them as well.  So we will not use this transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RemoveNumbersTransformer(TransformerMixin):\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_data(data_series):\n",
    "        \"\"\"\n",
    "        inspired from:\n",
    "        https://raw.githubusercontent.com/youngsoul/ml-twitter-sentiment-analysis/develop/cleanup.py\n",
    "        :param data_series:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # remove numbers\n",
    "        regex = re.compile(r\"\\s?[0-9]+\\.?[0-9]*\")\n",
    "        data_series.replace(regex, \"\", inplace=True)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: Series, aka column of data.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        RemoveNumbersTransformer._preprocess_data(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2862739473545161 Accuracy Diff: 0.0006004228022020164\n",
      "Transformed: 37954 Baseline: 38892 Feature Diff: -938\n"
     ]
    }
   ],
   "source": [
    "# Remove the user name, save the series in a new series and see if it helped the model\n",
    "rt = RemoveNumbersTransformer()\n",
    "test_transformer(rt, training_data.content.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Slight improvement, keep RemoveNumbersTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RemoveSpecialCharactersTransformer(TransformerMixin):\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_data(data_series):\n",
    "        \"\"\"\n",
    "        inspired from:\n",
    "        https://raw.githubusercontent.com/youngsoul/ml-twitter-sentiment-analysis/develop/cleanup.py\n",
    "        :param data_series:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # remove special characters\n",
    "        for remove in map(lambda r: re.compile(re.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                               \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                               \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                               \"!\", \"?\", \".\", \"'\",\n",
    "                                                               \"--\", \"---\", \"#\"]):\n",
    "            data_series.replace(remove, \"\", inplace=True)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: Series, aka column of data.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        RemoveSpecialCharactersTransformer._preprocess_data(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2804398102040787 Accuracy Diff: -0.005233714348235385\n",
      "Transformed: 43034 Baseline: 38892 Feature Diff: 4142\n"
     ]
    }
   ],
   "source": [
    "rt = RemoveSpecialCharactersTransformer()\n",
    "test_transformer(rt, training_data.content.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This transformer resulted in slightly worse performance, so we will not use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RemoveHtmlEncodedTransformer(TransformerMixin):\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_data(data_series):\n",
    "        \"\"\"\n",
    "        inspired from:\n",
    "        https://raw.githubusercontent.com/youngsoul/ml-twitter-sentiment-analysis/develop/cleanup.py\n",
    "        :param data_series:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # html encoded characters\n",
    "        for remove in map(lambda r: re.compile(r), [\"&lt;\", \"&gt;\", \"&quot;\", \"&amp;\", \"w/o\", \"w/\"]):\n",
    "            data_series.replace(remove, \"\", inplace=True)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: Series, aka column of data.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        RemoveHtmlEncodedTransformer._preprocess_data(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2854400243132305 Accuracy Diff: -0.00023350023908358386\n",
      "Transformed: 38954 Baseline: 38892 Feature Diff: 62\n"
     ]
    }
   ],
   "source": [
    "rt = RemoveHtmlEncodedTransformer()\n",
    "test_transformer(rt, training_data.content.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Slighty worse performance so we will not use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RemoveUrlsTransformer(TransformerMixin):\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess_data(data_series):\n",
    "        \"\"\"\n",
    "        inspired from:\n",
    "        https://raw.githubusercontent.com/youngsoul/ml-twitter-sentiment-analysis/develop/cleanup.py\n",
    "        :param data_series:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        # remove urls\n",
    "        regex = re.compile(r\"http.?://[^\\s]+[\\s]?\")\n",
    "        data_series.replace(regex, \"\", inplace=True)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: Series, aka column of data.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        RemoveUrlsTransformer._preprocess_data(X)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.28373921215917475 Accuracy Diff: -0.001934312393139348\n",
      "Transformed: 37666 Baseline: 38892 Feature Diff: -1226\n"
     ]
    }
   ],
   "source": [
    "rt = RemoveUrlsTransformer()\n",
    "test_transformer(rt, training_data.content.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Slightly worse so we will not use it.\n",
    "\n",
    "The only Transformers we will use are:\n",
    "> RemoveNumbersTransformer, RemoveUsernameTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29211011817381577 Accuracy Diff: 0.006436593621501674\n",
      "Transformed: 26085 Baseline: 38892 Feature Diff: -12807\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with the transformers we are keeping, and see the overall improvement.\n",
    "preprocessor_pipeline = make_pipeline(RemoveNumbersTransformer(), RemoveUsernameTransformer())\n",
    "test_transformer(preprocessor_pipeline, training_data.content.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Stemming to CountVectorizer to see if this helps\n",
    "\n",
    "Stemming can be added via NLTK or the stemming python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/AishwaryaRK/scikit-learn/commit/cb8afbc11fbe34c1378665040b605fb16784f77c\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    \n",
    "    def __init__(self, stemmer=None, input='content', encoding='utf-8',\n",
    "                 decode_error='strict', strip_accents=None,\n",
    "                 lowercase=True, preprocessor=None, tokenizer=None,\n",
    "                 stop_words=None, token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "                 ngram_range=(1, 1), analyzer='word',\n",
    "                 max_df=1.0, min_df=1, max_features=None,\n",
    "                 vocabulary=None, binary=False, dtype=np.int64):\n",
    "        super(StemmedCountVectorizer, self).__init__(\n",
    "            input=input, encoding=encoding, decode_error=decode_error,\n",
    "            strip_accents=strip_accents, lowercase=lowercase,\n",
    "            preprocessor=preprocessor, tokenizer=tokenizer, analyzer=analyzer,\n",
    "            stop_words=stop_words, token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range, max_df=max_df, min_df=min_df,\n",
    "            max_features=max_features, vocabulary=vocabulary, binary=binary,\n",
    "            dtype=dtype)        \n",
    "        self.stemmer = stemmer\n",
    "            \n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        if self.stemmer == None:\n",
    "            return analyzer\n",
    "        \n",
    "        return lambda doc: ([self.stemmer.stem(w) for w in analyzer(doc)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286609620222\n"
     ]
    }
   ],
   "source": [
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stemmed_count_vectorizer = StemmedCountVectorizer(stemmer=stemmer)\n",
    "\n",
    "# baseline pipeline.\n",
    "stem_pipeline = make_pipeline(stemmed_count_vectorizer, MultinomialNB())\n",
    "# Define the X and y variables\n",
    "X = training_data.content\n",
    "y = training_data.sentiment_num\n",
    "# cross-validate the entire pipeline\n",
    "baseline_accuracy = cross_val_score(stem_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the preprocessing pipeline and the Stemmed CountVectorizer into a single pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.296544703778\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with the transformers we are keeping, and see the overall improvement.\n",
    "# re-establish X and y\n",
    "X = training_data.content\n",
    "y = training_data.sentiment_num\n",
    "\n",
    "# create a pipeline of all of the steps we are currently keeping\n",
    "preprocessor_stem_pipeline = make_pipeline(RemoveNumbersTransformer(), RemoveUsernameTransformer(), StemmedCountVectorizer(stemmer=stemmer), MultinomialNB())\n",
    "\n",
    "# use cross validation on the pipeline to measure the accuracy.  Recall - we are using default parameters\n",
    "# for CountVectorizor and NB.\n",
    "preprocessor_stem_accuracy = cross_val_score(preprocessor_stem_pipeline, X, y, cv=5, scoring='accuracy').mean()\n",
    "print(preprocessor_stem_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Accuracy: 0.2866096202222253 PreProcess Stem Accuracy: 0.29654470377779213 Diff: 0.009935083555566826\n"
     ]
    }
   ],
   "source": [
    "print(\"Base Accuracy: {0} PreProcess Stem Accuracy: {1} Diff: {2}\".format(baseline_accuracy, preprocessor_stem_accuracy, (preprocessor_stem_accuracy - baseline_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune CountVectorizer\n",
    "\n",
    "Look at the different parameters for CountVectorizer and see if tuning those parameters help.  Also potentially look into TFIDF Vectorizer\n",
    "\n",
    "First, run the preprocessor_pipeline on the entire training data set.\n",
    "\n",
    "Second, create a model pipeline that will run through the CountVectorizer and the MultinomialNB model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "preprocessed_training_data = preprocessor_pipeline.transform(training_data)\n",
    "# Define new X and y variables\n",
    "X = preprocessed_training_data\n",
    "y = training_data.sentiment_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['stemmedcountvectorizer', 'multinomialnb'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline steps are automatically assigned names by make_pipeline\n",
    "stem_pipeline.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multinomialnb__alpha': [0.5, 1],\n",
       " 'stemmedcountvectorizer__max_df': [0.6, 0.8],\n",
       " 'stemmedcountvectorizer__min_df': [2, 3, 4, 5],\n",
       " 'stemmedcountvectorizer__ngram_range': [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
       " 'stemmedcountvectorizer__stop_words': ['english']}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['stemmedcountvectorizer__min_df'] = [2,3,4,5]\n",
    "param_grid['stemmedcountvectorizer__max_df'] = [0.6,0.8]\n",
    "param_grid['stemmedcountvectorizer__stop_words'] = ['english']\n",
    "param_grid['stemmedcountvectorizer__ngram_range'] = [(1,1),(1,2),(1,3),(1,4)]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(stem_pipeline, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time the grid search\n",
    "# %time grid.fit(X, y)\n",
    "\n",
    "#CPU times: user 2h 47min 34s, sys: 42.8 s, total: 2h 48min 17s\n",
    "#Wall time: 2h 49min 5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> CPU times: user 2h 47min 34s, sys: 42.8 s, total: 2h 48min 17s\n",
    "\n",
    "> Wall time: 2h 49min 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.3015\n",
      "Best Params: {'multinomialnb__alpha': 1, 'stemmedcountvectorizer__max_df': 0.6, 'stemmedcountvectorizer__min_df': 3, 'stemmedcountvectorizer__ngram_range': (1, 3), 'stemmedcountvectorizer__stop_words': 'english'}\n"
     ]
    }
   ],
   "source": [
    "# print the single best score and parameters that produced that score\n",
    "#print(grid.best_score_)\n",
    "#print(grid.best_params_)\n",
    "\n",
    "print(\"Best Score: 0.3015\")\n",
    "print(\"Best Params: {'multinomialnb__alpha': 1, 'stemmedcountvectorizer__max_df': 0.6, 'stemmedcountvectorizer__min_df': 3, 'stemmedcountvectorizer__ngram_range': (1, 3), 'stemmedcountvectorizer__stop_words': 'english'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 0.3015\n",
    "{'multinomialnb alpha': 1, 'stemmedcountvectorizer max_df': 0.6, 'stemmedcountvectorizer min_df': 3, 'stemmedcountvectorizer ngram_range': (1, 3), 'stemmedcountvectorizer stop_words': 'english'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmed CountVectorizer with Multinomial Naive Bayes Summary\n",
    "\n",
    "  - Multinomial NB alpha = 1\n",
    "  - stemmer = nltk.stem.SnowballStemmer('english')\n",
    "  - CountVectorizer max_df = 0.6\n",
    "  - CountVectorizer min_df = 3\n",
    "  - CountVectorizer ngram_range = (1,3)\n",
    "  - CountVectorizer stop_words = 'english'\n",
    "  \n",
    "The best score was 0.3015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemmed TF-IDF Vectorizer with LogisticRegression\n",
    "\n",
    "In a previous run, I did discover that the above combination was the best.  Lets try this combination to see if we can better the score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def __init__(self, stemmer=None, input='content', encoding='utf-8',\n",
    "                 decode_error='strict', strip_accents=None, lowercase=True,\n",
    "                 preprocessor=None, tokenizer=None, analyzer='word',\n",
    "                 stop_words=None, token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "                 ngram_range=(1, 1), max_df=1.0, min_df=1,\n",
    "                 max_features=None, vocabulary=None, binary=False,\n",
    "                 dtype=np.int64, norm='l2', use_idf=True, smooth_idf=True,\n",
    "                 sublinear_tf=False):\n",
    "\n",
    "        super(StemmedTfidfVectorizer, self).__init__(\n",
    "            input=input, encoding=encoding, decode_error=decode_error,\n",
    "            strip_accents=strip_accents, lowercase=lowercase,\n",
    "            preprocessor=preprocessor, tokenizer=tokenizer, analyzer=analyzer,\n",
    "            stop_words=stop_words, token_pattern=token_pattern,\n",
    "            ngram_range=ngram_range, max_df=max_df, min_df=min_df,\n",
    "            max_features=max_features, vocabulary=vocabulary, binary=binary,\n",
    "            dtype=dtype, norm='l2', use_idf=True, smooth_idf=True,\n",
    "                             sublinear_tf=False)\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([self.stemmer.stem(w) for w in analyzer(doc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# re- read the training data\n",
    "training_data = pd.read_csv('../data/kaggle/sa-emotions/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@Sageey My public talk in July got canceled and I don't know why.</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Epic ocd moment? I deleted my sims file that i spent hours building just because i set his favorite food wrong</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>worry</td>\n",
       "      <td>[BBC] Malaria parasites becoming resistant to drugs  http://trunc.it/9yn5 ~ this is really not good as Malaria affects so many people</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>my to do list is bananas, before i leave for Europe BOOOO</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>darn it. I did it again.!  keep forgetting that darn &amp;quot;D&amp;quot; for DM's.....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@chelsea_playboy R.I.P curls</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@Jeanise  I was going to say let's go to lunch...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>argh! why why why</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@vronmcintyre I want an espresso machine</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>love</td>\n",
       "      <td>@Crazy_Cindy  BIG HUGGS</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11000</th>\n",
       "      <td>worry</td>\n",
       "      <td>is wondering y Mother Nature is making my life miserable</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>happiness</td>\n",
       "      <td>Just got my paycheck... April bonus can b deposited 2day the rest, gotta wait til Mon.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13000</th>\n",
       "      <td>worry</td>\n",
       "      <td>I don't feel good.  .My throat hurts!!!!</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@QuindaS  your right.... How was your trip</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@RealJessicaAlba Is it true there won't be any Fantastic 4 sequels?  I wished they introduced a Franklin Richards character... will they?</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>hate</td>\n",
       "      <td>I hate waiting in lines</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@dunnybrasco Im home, phone died thou</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18000</th>\n",
       "      <td>worry</td>\n",
       "      <td>is gonna be mad hungry when I get home. Forgot my money...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19000</th>\n",
       "      <td>sadness</td>\n",
       "      <td>really tired. and have to work the whole day tomorrow, the thought of it depresses me.  uncoooool....</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000</th>\n",
       "      <td>empty</td>\n",
       "      <td>Thanks for pointing out the crucial problems @thakkar. Both of them have been taken care of  (cc: @Netra)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@KatieAlender ooh which two books did you buy?</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22000</th>\n",
       "      <td>empty</td>\n",
       "      <td>@greyeyesgabriel You are clearly very busy  Take care of yourself, and I am sure you will be fine; takes one to know one ;)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23000</th>\n",
       "      <td>relief</td>\n",
       "      <td>is back in fine old melbourne town....</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24000</th>\n",
       "      <td>hate</td>\n",
       "      <td>@girltrumpet yeahh  idk if i like owen anymore though... i kinda lost respect for him in an episode i recorded...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>fun</td>\n",
       "      <td>'Look at the tadpole'... 'No! ... Look at me!!!' ... Foolish dog  http://yfrog.com/05ixbj</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26000</th>\n",
       "      <td>surprise</td>\n",
       "      <td>@azkikah the idiom?? doesn't ring a bell eh? hahaha. y'are really thinking of food?! nope. actually in the bathroom. teehee</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27000</th>\n",
       "      <td>empty</td>\n",
       "      <td>@sugarrae i thought you would win!  Fabulously40 have some bots on her side?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28000</th>\n",
       "      <td>worry</td>\n",
       "      <td>@AnnebrittB slaying dragons &amp;amp; rescue innocents, this could be a good life movie   Make sure to take a camara and film!!!!</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29000</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@jareason left a comment on your blog post</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment  \\\n",
       "0          empty   \n",
       "1000       worry   \n",
       "2000     sadness   \n",
       "3000       worry   \n",
       "4000     neutral   \n",
       "5000     sadness   \n",
       "6000     neutral   \n",
       "7000     neutral   \n",
       "8000     sadness   \n",
       "9000       worry   \n",
       "10000       love   \n",
       "11000      worry   \n",
       "12000  happiness   \n",
       "13000      worry   \n",
       "14000    neutral   \n",
       "15000   surprise   \n",
       "16000       hate   \n",
       "17000      worry   \n",
       "18000      worry   \n",
       "19000    sadness   \n",
       "20000      empty   \n",
       "21000    neutral   \n",
       "22000      empty   \n",
       "23000     relief   \n",
       "24000       hate   \n",
       "25000        fun   \n",
       "26000   surprise   \n",
       "27000      empty   \n",
       "28000      worry   \n",
       "29000    neutral   \n",
       "\n",
       "                                                                                                                                         content  \\\n",
       "0                                                   @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1000                                                                           @Sageey My public talk in July got canceled and I don't know why.   \n",
       "2000                              Epic ocd moment? I deleted my sims file that i spent hours building just because i set his favorite food wrong   \n",
       "3000       [BBC] Malaria parasites becoming resistant to drugs  http://trunc.it/9yn5 ~ this is really not good as Malaria affects so many people   \n",
       "4000                                                                                   my to do list is bananas, before i leave for Europe BOOOO   \n",
       "5000                                                            darn it. I did it again.!  keep forgetting that darn &quot;D&quot; for DM's.....   \n",
       "6000                                                                                                                @chelsea_playboy R.I.P curls   \n",
       "7000                                                                                           @Jeanise  I was going to say let's go to lunch...   \n",
       "8000                                                                                                                           argh! why why why   \n",
       "9000                                                                                                    @vronmcintyre I want an espresso machine   \n",
       "10000                                                                                                                    @Crazy_Cindy  BIG HUGGS   \n",
       "11000                                                                                   is wondering y Mother Nature is making my life miserable   \n",
       "12000                                                     Just got my paycheck... April bonus can b deposited 2day the rest, gotta wait til Mon.   \n",
       "13000                                                                                                   I don't feel good.  .My throat hurts!!!!   \n",
       "14000                                                                                                 @QuindaS  your right.... How was your trip   \n",
       "15000  @RealJessicaAlba Is it true there won't be any Fantastic 4 sequels?  I wished they introduced a Franklin Richards character... will they?   \n",
       "16000                                                                                                                    I hate waiting in lines   \n",
       "17000                                                                                                      @dunnybrasco Im home, phone died thou   \n",
       "18000                                                                                 is gonna be mad hungry when I get home. Forgot my money...   \n",
       "19000                                      really tired. and have to work the whole day tomorrow, the thought of it depresses me.  uncoooool....   \n",
       "20000                                  Thanks for pointing out the crucial problems @thakkar. Both of them have been taken care of  (cc: @Netra)   \n",
       "21000                                                                                             @KatieAlender ooh which two books did you buy?   \n",
       "22000                @greyeyesgabriel You are clearly very busy  Take care of yourself, and I am sure you will be fine; takes one to know one ;)   \n",
       "23000                                                                                                     is back in fine old melbourne town....   \n",
       "24000                          @girltrumpet yeahh  idk if i like owen anymore though... i kinda lost respect for him in an episode i recorded...   \n",
       "25000                                                  'Look at the tadpole'... 'No! ... Look at me!!!' ... Foolish dog  http://yfrog.com/05ixbj   \n",
       "26000                @azkikah the idiom?? doesn't ring a bell eh? hahaha. y'are really thinking of food?! nope. actually in the bathroom. teehee   \n",
       "27000                                                               @sugarrae i thought you would win!  Fabulously40 have some bots on her side?   \n",
       "28000              @AnnebrittB slaying dragons &amp; rescue innocents, this could be a good life movie   Make sure to take a camara and film!!!!   \n",
       "29000                                                                                                 @jareason left a comment on your blog post   \n",
       "\n",
       "       sentiment_num  \n",
       "0                  2  \n",
       "1000              12  \n",
       "2000              10  \n",
       "3000              12  \n",
       "4000               8  \n",
       "5000              10  \n",
       "6000               8  \n",
       "7000               8  \n",
       "8000              10  \n",
       "9000              12  \n",
       "10000              7  \n",
       "11000             12  \n",
       "12000              5  \n",
       "13000             12  \n",
       "14000              8  \n",
       "15000             11  \n",
       "16000              6  \n",
       "17000             12  \n",
       "18000             12  \n",
       "19000             10  \n",
       "20000              2  \n",
       "21000              8  \n",
       "22000              2  \n",
       "23000              9  \n",
       "24000              6  \n",
       "25000              4  \n",
       "26000             11  \n",
       "27000              2  \n",
       "28000             12  \n",
       "29000              8  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the sentiment outcomes as a number using the LabelEncoder\n",
    "# would like to create a column, e.g. sentiment_num, which is a numeric representation of the sentiment.\n",
    "# this will have to also be applied to any test data.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# fit the label encoder with the unique set of sentiments in the training data.\n",
    "label_encoder.fit(training_data.sentiment.unique())\n",
    "# planning ahead, create a function to create features in a data set that we will have to create in \n",
    "# both the training and testing data\n",
    "def make_features(df, sentiment_num_encoder):\n",
    "    training_data['sentiment_num'] = training_data.sentiment.apply(lambda x: label_encoder.transform([x])[0])\n",
    "    \n",
    "make_features(training_data, sentiment_num_encoder=label_encoder)\n",
    "training_data[::1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a pipeline with the transformers we are keeping, and see the overall improvement.\n",
    "preprocessor_pipeline = make_pipeline(RemoveNumbersTransformer(), RemoveUsernameTransformer())\n",
    "\n",
    "# create stemmer\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "# 0.3145 stemmed_tfidf_vectorizer = StemmedTfidfVectorizer(stemmer=stemmer, min_df=5, max_df=0.8, ngram_range=(1,4), sublinear_tf=True,  stop_words='english')\n",
    "stemmed_tfidf_vectorizer = StemmedTfidfVectorizer(stemmer=stemmer, min_df=5, max_df=0.8, ngram_range=(1,4), stop_words='english')\n",
    "\n",
    "# baseline pipeline.\n",
    "tfidf_stem_pipeline = make_pipeline(stemmed_tfidf_vectorizer, LogisticRegression(C=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessed_training_data = preprocessor_pipeline.transform(training_data.content)\n",
    "# Define new X and y variables\n",
    "X = preprocessed_training_data\n",
    "y = training_data.sentiment_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000,)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i know  i was listenin to bad habit earlier and i started freakin at his part =[\n",
       "1                        Layin n bed with a headache  ughhhh...waitin on your call...\n",
       "2                                                 Funeral ceremony...gloomy friday...\n",
       "3                                                wants to hang out with friends SOON!\n",
       "4             We want to trade with someone who has Houston tickets, but no one will.\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'stemmedtfidfvectorizer__sublinear_tf': [False, True]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['stemmedtfidfvectorizer__sublinear_tf'] = [False, True]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(tfidf_stem_pipeline, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# time the grid search\n",
    "# comment out because we do not want to run every time. %time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.3153\n",
      "Best Params: {'stemmedtfidfvectorizer__sublinear_tf': True}\n"
     ]
    }
   ],
   "source": [
    "# print the single best score and parameters that produced that score\n",
    "#print(grid.best_score_)\n",
    "#print(grid.best_params_)\n",
    "\n",
    "print(\"Best Score: 0.3153\")\n",
    "print(\"Best Params: {'stemmedtfidfvectorizer__sublinear_tf': True}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Conclusion\n",
    "\n",
    "It appears that a Stemmed TFIDFVectorizer, and LogisticRegression are so far the best combination.\n",
    "\n",
    "Below is the summarized pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a pipeline with the transformers we are keeping, and see the overall improvement.\n",
    "preprocessor_pipeline = make_pipeline(RemoveNumbersTransformer(), RemoveUsernameTransformer())\n",
    "\n",
    "# create stemmer\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stemmed_tfidf_vectorizer = StemmedTfidfVectorizer(stemmer=stemmer, min_df=5, max_df=0.8, ngram_range=(1,4), stop_words='english', sublinear_tf=True)\n",
    "\n",
    "# baseline pipeline.\n",
    "tfidf_stem_pipeline = make_pipeline(stemmed_tfidf_vectorizer, LogisticRegression(C=0.1))\n",
    "preprocessed_training_data = preprocessor_pipeline.transform(training_data)\n",
    "# Define new X and y variables\n",
    "X = preprocessed_training_data.content\n",
    "y = training_data.sentiment_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "The block below is a summary of all of the steps in one place for a simple review.  It was decided to go with LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mark_negation_sentence(sentence):\n",
    "    \"\"\"\n",
    "    This function will take a sentence in, split it and call mark_negation, and \n",
    "    puts the string back together again.  \n",
    "    \n",
    "    Append _NEG suffix to words that appear in the scope between a negation\n",
    "    and a punctuation mark.\n",
    "    \n",
    "    :param sentence an entire sentence\n",
    "    :return sentence with the negation marked\n",
    "    \"\"\"\n",
    "    return \" \".join(mark_negation(sentence.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anger', 'boredom', 'empty', 'enthusiasm', 'fun', 'happiness', 'hate', 'love', 'neutral', 'relief', 'sadness', 'surprise', 'worry']\n",
      "Train document term maxtrix: (22500, 6368)\n",
      "Test document term maxtrix: (7500, 6368)\n",
      "CPU times: user 1.42 s, sys: 16.9 ms, total: 1.44 s\n",
      "Wall time: 1.46 s\n",
      "Accuracy: 0.3294666666666667\n"
     ]
    }
   ],
   "source": [
    "# Now that we have an idea of what model we want to use, create a more traditional, train_test_split and\n",
    "# look at things like the confusion matrix, etc\n",
    "\n",
    "    \n",
    "# read in the training data\n",
    "training_data = pd.read_csv('../data/kaggle/sa-emotions/train_data.csv')\n",
    "\n",
    "# encode the sentiment outcomes as a number using the LabelEncoder\n",
    "# would like to create a column, e.g. sentiment_num, which is a numeric representation of the sentiment.\n",
    "# this will have to also be applied to any test data.\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# fit the label encoder with the unique set of sentiments in the training data.\n",
    "label_encoder.fit(training_data.sentiment.unique())\n",
    "\n",
    "# print out what classes were discovered\n",
    "print(list(label_encoder.classes_))\n",
    "\n",
    "\n",
    "# add the sentiment_num column\n",
    "training_data['sentiment_num'] = training_data.sentiment.apply(lambda x: label_encoder.transform([x])[0])\n",
    "\n",
    "# Create a pipeline with the transformers we are keeping, and see the overall improvement.\n",
    "preprocessor_pipeline = make_pipeline(RemoveNumbersTransformer(), RemoveUsernameTransformer())\n",
    "preprocessed_training_data_content = preprocessor_pipeline.transform(training_data.content)\n",
    "\n",
    "#print(training_data.content.head(300))\n",
    "\n",
    "# Define new X and y variables\n",
    "# Apply the mark negation transformer to the data set.\n",
    "X = training_data.content.apply(mark_negation_sentence)\n",
    "y = training_data.sentiment_num\n",
    "\n",
    "# just to see the _NEG work print(X[:100])\n",
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)\n",
    "\n",
    "# create stemmer and vectorizer\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stemmed_tfidf_vectorizer = StemmedTfidfVectorizer(stemmer=stemmer, min_df=5, max_df=0.8, ngram_range=(1,4), stop_words='english', sublinear_tf=True)\n",
    "\n",
    "# establish the vocabulary\n",
    "stemmed_tfidf_vectorizer.fit(X_train)\n",
    "\n",
    "# create the document term matrix\n",
    "X_train_dtm = stemmed_tfidf_vectorizer.transform(X_train)\n",
    "\n",
    "# create a test document-term matrix\n",
    "X_test_dtm = stemmed_tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"Train document term maxtrix: {}\".format(X_train_dtm.shape))\n",
    "print(\"Test document term maxtrix: {}\".format(X_test_dtm.shape))\n",
    "\n",
    "# create LogisticRegression Model\n",
    "model = LogisticRegression(C=0.1)\n",
    "\n",
    "#model = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)\n",
    "\n",
    "# train the model using the X_train_dtm\n",
    "%time model.fit(X_train_dtm, y_train)\n",
    "\n",
    "# make predictions on the test document \n",
    "y_predictions = model.predict(X_test_dtm)\n",
    "\n",
    "# calculation accuracy\n",
    "accuracy = metrics.accuracy_score(y_test, y_predictions)\n",
    "\n",
    "print(\"Accuracy: {}\".format(accuracy))\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    5    0    1    0   16]\n",
      " [   0    0    0    0    0    0    0    0    8    0    3    0   23]\n",
      " [   0    0    0    0    0    1    0    0   73    0    6    0   83]\n",
      " [   0    0    0    0    0    4    0    1   52    0    4    0   61]\n",
      " [   0    0    0    0    0   10    0    6  131    0    5    0  120]\n",
      " [   0    0    0    0    0   84    0   15  407    0    8    0  279]\n",
      " [   0    0    0    0    0    0    8    0   84    0   12    0  200]\n",
      " [   0    0    0    0    0   38    0   68  224    0   22    0  192]\n",
      " [   0    0    0    0    0   31    2   19  807    0   32    0  628]\n",
      " [   0    0    0    0    0    9    0    3  108    0    5    0  131]\n",
      " [   0    0    0    0    0    4    1   11  263    0  131    0  775]\n",
      " [   0    0    0    0    0    9    0    5  126    0    7    0  221]\n",
      " [   0    0    0    0    0   10    1   10  433    0   91    0 1373]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://gist.github.com/zachguo/10296432\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print(\"    \" + empty_cell, end=\" \")\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    anger    boredom      empty enthusiasm        fun  happiness       hate       love    neutral     relief    sadness   surprise      worry \n",
      "         anger        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        5.0        0.0        1.0        0.0       16.0 \n",
      "       boredom        0.0        0.0        0.0        0.0        0.0        0.0        0.0        0.0        8.0        0.0        3.0        0.0       23.0 \n",
      "         empty        0.0        0.0        0.0        0.0        0.0        1.0        0.0        0.0       73.0        0.0        6.0        0.0       83.0 \n",
      "    enthusiasm        0.0        0.0        0.0        0.0        0.0        4.0        0.0        1.0       52.0        0.0        4.0        0.0       61.0 \n",
      "           fun        0.0        0.0        0.0        0.0        0.0       10.0        0.0        6.0      131.0        0.0        5.0        0.0      120.0 \n",
      "     happiness        0.0        0.0        0.0        0.0        0.0       84.0        0.0       15.0      407.0        0.0        8.0        0.0      279.0 \n",
      "          hate        0.0        0.0        0.0        0.0        0.0        0.0        8.0        0.0       84.0        0.0       12.0        0.0      200.0 \n",
      "          love        0.0        0.0        0.0        0.0        0.0       38.0        0.0       68.0      224.0        0.0       22.0        0.0      192.0 \n",
      "       neutral        0.0        0.0        0.0        0.0        0.0       31.0        2.0       19.0      807.0        0.0       32.0        0.0      628.0 \n",
      "        relief        0.0        0.0        0.0        0.0        0.0        9.0        0.0        3.0      108.0        0.0        5.0        0.0      131.0 \n",
      "       sadness        0.0        0.0        0.0        0.0        0.0        4.0        1.0       11.0      263.0        0.0      131.0        0.0      775.0 \n",
      "      surprise        0.0        0.0        0.0        0.0        0.0        9.0        0.0        5.0      126.0        0.0        7.0        0.0      221.0 \n",
      "         worry        0.0        0.0        0.0        0.0        0.0       10.0        1.0       10.0      433.0        0.0       91.0        0.0     1373.0 \n"
     ]
    }
   ],
   "source": [
    "print_cm(confusion_matrix, list(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Screen capture of the confusion matrix in an easier to read form\n",
    "\n",
    "![Clean Confusion Matrix](confusion_matrix.png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10747</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12573</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29676</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8856</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21098</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17458</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5120</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18338</th>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28279</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_pred  y_test\n",
       "10747      12       6\n",
       "12573      12       8\n",
       "29676       8       8\n",
       "8856       12      10\n",
       "21098       5       5\n",
       "17458      12      12\n",
       "1476       12       8\n",
       "5120       10       8\n",
       "18338      12       5\n",
       "28279       8       9"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data frame that shows the predicted and actual test values so we can easily \n",
    "# compare the predicted and actual.\n",
    "results_df = pd.DataFrame({'y_test': y_test, 'y_pred': y_predictions})\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12573                                                                                                                                                                               Must head back to the office\n",
       "1476                                                                                                                                                                                              crash in Qmbol\n",
       "20371    not sure_NEG I_NEG like_NEG this_NEG way_NEG to_NEG learn_NEG a_NEG new_NEG language_NEG I_NEG prefer_NEG to_NEG be_NEG &quot;on_NEG location&quot;,_NEG so_NEG I_NEG can_NEG practice,_NEG ask_NEG ...\n",
       "4984                                                                                                                        i love how nice the weather is today and i am camping tonight! oh and i hate my hair\n",
       "21382                                                                                                                                    I think that's the Muji stabilo. Because she was eyeing mine last week.\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false negative anger\n",
    "# y_test is anger, but the prediction is not anger.\n",
    "# look at the resulting strings and try to see what we can do to make a better anger prediction\n",
    "tp_anger = X_test[(results_df.y_test == 8) & (results_df.y_pred == 12) ]\n",
    "tp_anger.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment               neutral\n",
      "content          crash in Qmbol\n",
      "sentiment_num                 8\n",
      "Name: 1476, dtype: object\n",
      "sentiment                                                                         neutral\n",
      "content          I think that's the Muji stabilo.  Because she was eyeing mine last week.\n",
      "sentiment_num                                                                           8\n",
      "Name: 21382, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(training_data.loc[1476])\n",
    "print(training_data.loc[21382])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3551                                                                              why im not sleeping_NEG !!_NEG\n",
       "12549                             Man i am being boring today not tweeting_NEG How_NEG are_NEG you_NEG guys?_NEG\n",
       "19862    -Pendulum = awesome!-Goodbyes suck -Shut up plz.-Toy Story!! -JBD MOVIEMORO!-I'm tired.-Aaaand I'm out.\n",
       "8670                                                              One hour and fifteen minutes. A dreadful wait.\n",
       "6653                                                     Really bored tonight though Your book I think (Y) xxxxx\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false negative boredom\n",
    "pred_class_num = 1\n",
    "tp_boredom = X_test[(results_df.y_test == pred_class_num) & (results_df.y_pred != pred_class_num)]\n",
    "tp_boredom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "False Negatives for class: 0 anger\n",
      "527                                                                                                                                                   Working But it's Fridaaaayyyyy\n",
      "2664                                                                                                                                            lost all my files since high school.\n",
      "14082                                                                                                         sam and sean are teasing me saying they are gonna get wings without me\n",
      "6895                has a VERY arduous task to accomplish at work...stuff that should have already been done &amp; as usual it hasn't. Not_NEG because_NEG of_NEG me_NEG either._NEG\n",
      "4511                                                                                       The toaster oven was my fault. Now I'm going to look like an idiot in front of my father.\n",
      "2135                                                                                       My stomach is all EXPLODE from the wendys why is everything that tastes good bad for you?\n",
      "7767                                                                                                                                            studying for this bullshit econ test\n",
      "20734                                                                                     http://twitpic.com/j - Guess I need to get me an iPhone now for sure!!! It looks bad ass!!\n",
      "7205     Murphy's Law? Sorry that your computer is not cooperating_NEG when_NEG you_NEG have_NEG lots_NEG of_NEG work._NEG My_NEG kids_NEG are_NEG .._NEG http://tinyurl.com/kmx_NEG\n",
      "612                                                                                                                                                Packing I don't like_NEG it.._NEG\n",
      "12996                                                                                                                                             Why do you not respond_NEG me?_NEG\n",
      "13041                                                                                                          Big Laptop is too big, so it's time to switch to the Eee. Bye big guy\n",
      "18851                                                                                                                                                 too sick for rigging tomorrow.\n",
      "17521                                                                                              Apperently ea knows my copy of the sims is not legit_NEG and_NEG is_NEG upset_NEG\n",
      "1377                                                                               I tried to dye my hair and all i got was a blond chunk in the front middle part of my hair. Dang.\n",
      "17243                                                                                                                                   I am beginning to think sun blcok is a haox.\n",
      "3337                                                                                                 If you don't want_NEG to_NEG come_NEG then_NEG don't_NEG come._NEG JEEEEEZ._NEG\n",
      "19224                                                                                                             UUUUUGH!!! I HATE I MISSED INTERVIEW!!! I WASNT AT HOME!!! DARN!!!\n",
      "9998                                                                                                                         #twitterfails fucking hard right now...this is annoying\n",
      "10734                                                                                                                         bout to go to work with a wicked sunburn on the chest.\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 1 boredom\n",
      "3551                                                                                                                                          why im not sleeping_NEG !!_NEG\n",
      "12549                                                                                         Man i am being boring today not tweeting_NEG How_NEG are_NEG you_NEG guys?_NEG\n",
      "19862                                                                -Pendulum = awesome!-Goodbyes suck -Shut up plz.-Toy Story!! -JBD MOVIEMORO!-I'm tired.-Aaaand I'm out.\n",
      "8670                                                                                                                          One hour and fifteen minutes. A dreadful wait.\n",
      "6653                                                                                                                 Really bored tonight though Your book I think (Y) xxxxx\n",
      "345                                                                                                                                   why did i agree to work a double shift\n",
      "27057                                                                                                                               Aboutpm. Squeaking?! Hell squeaking?! D:\n",
      "9399                                                           jus sittin in da libray and this stupid computer wont let_NEG me_NEG order_NEG any_NEG mac_NEG foundation_NEG\n",
      "1104                                                                                                                       Tweeting from the tarmac at Cork Airport. Delayed\n",
      "11799                                                                                                sitting at the chevy dealership in utah waiting for the van to be fixed\n",
      "15588                                                                                                                            buuuut its so annoying!! okay *breathes* x.\n",
      "10503    Were you going to come? The venue said that they couldn't afford_NEG to_NEG open_NEG so_NEG cancelled_NEG it._NEG I_NEG wish_NEG we_NEG were_NEG there_NEG now!_NEG\n",
      "18292                                                                            Same! Like the kisses on nights when she wasnt up for eviction! They were very badly edited\n",
      "5145                                                                                                                                       i dislike math, but math HATES me\n",
      "14124                                                                 is tired.: alarm setting will do that Off to bed as soon as my bloody iPhone Backup and Sync finishes.\n",
      "12044                                                                                                    Ditto that, my friend...BORED! Oops, now I have an exciting problem\n",
      "11344                                                                           i don't know_NEG what_NEG to_NEG do..._NEG time_NEG is_NEG going_NEG by_NEG so_NEG fast._NEG\n",
      "11321                                                                                                 need some more enthu movie guys for that. Right now it's just you, and\n",
      "6868                                                                                                   The gigantic initial inertial to get oneself to work after a deadline\n",
      "2674                                                       fo shizzle. . . i'm bored and wanna go do something. wish i went to pisay today. oh wellz. wonder who were there.\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 2 empty\n",
      "10212                                                                                                                                                                          i gotta say, i'm a little jealous\n",
      "29124                                                                                                                              #pens...steigy...no politics hun...the obamas are not watching_NEG hockey_NEG\n",
      "15517                                                                   awww my trini no esata_NEG bien_NEG bendito_NEG too_NEG bad_NEG i_NEG cant_NEG fly_NEG in_NEG and_NEG make_NEG u_NEG feel_NEG better_NEG\n",
      "12893                                                                                                                                          http://twurl.nl/goljwp is what i get when i try to add a new post\n",
      "17204                                                                                                                                                                                   it's raining I'm hiding.\n",
      "29970                                                                                                                                                                                             oui ta soeur!!\n",
      "29684                                                                                                                                                                                          Plan, successful?\n",
      "8341                                                                                                                                                FML i just spilled my entire can of diet coke IN MY LAP. yay\n",
      "21351                                                                       *waves* not quite_NEG some_NEG of_NEG us_NEG are_NEG still_NEG lounging_NEG around_NEG How_NEG are_NEG you_NEG this_NEG morning?_NEG\n",
      "8849                                                                                                               When God created man i also believed he created a million people to get on ya tits for a laff\n",
      "12479                                                                                                                 days of summer holiday left, and they are going way too slow! When will school get here???\n",
      "24853    no. dont really_NEG mean_NEG anything_NEG to_NEG me_NEG anymore_NEG :L_NEG it_NEG did_NEG when_NEG good_NEG old_NEG top_NEG of_NEG the_NEG pops_NEG was_NEG on_NEG every_NEG sat_NEG or_NEG friday_N...\n",
      "3588                                                 friends romans and country men lol ppl need help me out and say i have twitter i dont have_NEG any_NEG friends_NEG loner_NEG loner_NEG la_NEG da_NEG da_NEG\n",
      "29075                                                                            Trying to figure out what to do tonight. See the game? Social events w. friends? Or stay home and play the s**t out of my drums\n",
      "11960                                                                                                                                                  Just came back from school.... Packing for my dad's house\n",
      "17795                                                                                                                                                                  Trader Joe's &quot;sushi&quot; is a fail.\n",
      "19927                                                                                                                                                                                                    sa'weee\n",
      "16259                                                                                                                                No fun Well hopefully you don't have_NEG much_NEG more_NEG to_NEG go..._NEG\n",
      "14447                                                                                                                                                  Lost a battle with the couch....phone has been blowing up\n",
      "15270                                                                                                              Maybe i won't go_NEG for_NEG a_NEG run_NEG .._NEG i_NEG have_NEG no_NEG running_NEG shoes_NEG\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 3 enthusiasm\n",
      "3608                                                                                well us Brits have to wait a few more days for it! I thought it was all gonna released at once! I guess it's worth the wait!\n",
      "23887                                                                                                                                            Press 'Ctrl' on bottom right. The underscore for E is there. KY\n",
      "24476                                                                                                                                                                                 I want to see David cook!!\n",
      "11548                                                                                                                                              Interesting... I never get_NEG to_NEG Etown,_NEG however._NEG\n",
      "23712         ooohhh. I understand. I never get_NEG sick_NEG of_NEG her_NEG so_NEG im_NEG on_NEG your_NEG moms_NEG side_NEG I_NEG guess_NEG your_NEG dad_NEG just_NEG likes_NEG what_NEG he_NEG likes....lol_NEG\n",
      "12471                                                                                                                                                    last day of work ...but everyone is making it so great!\n",
      "27497                                                                                          thanks for a nice blog post! should however be given some creds since he has done at least half of the work on it\n",
      "27342                                                                                                                                                            Well....hopefully someday soon you can get one!\n",
      "22790                                                                                                                                                                 I hope you're tired for a good reason then\n",
      "27079                                                                                                                    ... Lol! Probably a little sweeter in the carribbean! Tropical island sounds wonderful.\n",
      "28609                                                                                                                                            haaah, making the card for mothers day, and listening to musicc\n",
      "24037                                                                                                                                                add me on myspace?? www.myspace.com/pwnage_org -&gt; pcFOpc\n",
      "21246                                                                                                                                   I really like pink after I saw her live while in the new T-MOBILE Advert\n",
      "28672                                                                                                                                                                Yep, that B-Day kiss is gonna happen, right\n",
      "21444                                                                                                                                                            you outta follow zipz for discounts and updates\n",
      "12209                                                                                                                       Nice seeing my partner in crime/gossip drama queen partner again. I missed my Manda!\n",
      "1928                                                                                 Getting ready for work and the sun is shining, plus it's the w/e! Bgt tonight..... what am I gonna do after it's finished?!\n",
      "10180                                                                                                                              Even without the dressing they're still over calories. I love that flatbread.\n",
      "20007    holllaaa.. i dont know_NEG what_NEG ur_NEG up_NEG doing_NEG but_NEG im_NEG trying_NEG to_NEG finish_NEG up_NEG some_NEG work_NEG for_NEG school..._NEG bout_NEG to_NEG go_NEG to_NEG bed_NEG though_NEG\n",
      "15235                                                                                                                   - Gig was awesome! Am exahausted and so dont want_NEG to_NEG revise_NEG Boo_NEG Hoo!_NEG\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 4 fun\n",
      "7526          haha well i was at my friend's party, but then i realized i forgot my stepmom's bday, so i had to come home to call her!\n",
      "16577                                                                   word is marlon brando gave him cent . . . yeah , tha GODFATHER\n",
      "16997             Rehearsal is done we had SO MUCH FUUN. hide&amp;seek tag and we learned BOMB DANCES , going home and doing hw maybe!\n",
      "5670                                                                                           really wanted to go to that gig tonight\n",
      "24051                                 haha well have fun at school! I'm gonna be sittin' at home with my italian restaurant by my side\n",
      "26788                                                                        hehe now im smiling... but u still gotta make it up to me\n",
      "29390                                                                                                                            yeahh\n",
      "25858                                                                         Presentation - done! And btw: my teacher is cute as hell\n",
      "28079    true true, I'm writing atm, trying b coherent about the last yrs&amp;string narratives through it but my meats rotting nicely\n",
      "21876                                      i guess i'll do both since i cant really_NEG decide_NEG which_NEG one_NEG to_NEG choose_NEG\n",
      "29826                                                                                                 Your such a riot!! You go girl!!\n",
      "12388                                                                                                         getting ready to babysit\n",
      "12512                                                                            omgggg!! Hawaii!! That's amazing!! I wanna live there\n",
      "22250                                                      #momoTLV is always good IVA will have a special price for #momoTLV guests..\n",
      "17637        I think I already regret telling rick I have an xbox... I'm losing him to that and twitter.. you still want it jimbo haha\n",
      "23821                                                                 i thinks thats right lol... please follow me... much appreciated\n",
      "21630                                                             In France it was last Friday and also the coming one, we are working\n",
      "11619                                                                            Draven's elbow met cement this afternoon Looks nasty.\n",
      "27461                                                                  its funny, I didn't even_NEG know_NEG it_NEG was_NEG there!_NEG\n",
      "5226               i got coupons to Popeye's chicken but I'll probably end up getting a burrito at freshii - this salad joint. healthy\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 5 happiness\n",
      "18338                                               Thx had a great day &amp; gonna have a long weekend. Excited yet I'll be missin my tweeple badly.\n",
      "21810                                                                                                                   aww preciate the loves hunnie\n",
      "23746                                                                                             Wow, it's so early. Just had the best conversation.\n",
      "6490                                                                                              My Degree [Tear] happy moment! http://mypict.me/ZpF\n",
      "21658                                                    muhahaha you've joined the tweet cult... lol heya btw twitterific is a good iphone app i use\n",
      "21914                                                                                                                 to and thanks for following me.\n",
      "25355                                                                                                                         Saturday is Partytiiime\n",
      "24349                                                                                                     U r welcome pal u truly deserve be followed\n",
      "23721                               Itsurely will dear . in posted a presentation on Swine flu yest and it got downloads in just a day!!i feels great\n",
      "27888    oh yeah...haven't seem_NEG that_NEG in_NEG ages!!_NEG got_NEG to_NEG watch_NEG that_NEG soon!!_NEG thanks_NEG for_NEG reminding_NEG me!!_NEG\n",
      "18583                                                                                                              good job! I wish i worked in a zoo\n",
      "23409                                                                                                                                          Agree!\n",
      "14432                                        just saw UP it was a cute movie (:passed by a place called a peasants kitchen. wtf? that names kinda sad\n",
      "25579                                                                                                                              goooooood morning!\n",
      "28325                  all pugged in and ready to go. device updates on, so feel free to bombard me at any time. Time to actually get something done.\n",
      "4499                                                                              hahaha well why would you smack ME for that?! hahaha THE BIG BANGGG\n",
      "543                                     My little foster kittens are getting big...chubba and Winston are going b missed when they get amazing homes.\n",
      "12630                                                                              Being followed by compliance. Great. Have to watch what I say now.\n",
      "11008                                                                                                   hanging out at school... last day for seniors\n",
      "3858                     Now that I have a salary, I can actually spend money. Hooray! Time to go shopping and have dinner at Ahora to say goodbye to\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 6 hate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10747                                                                                                                                                                              Walmart bails on sponsorship!\n",
      "27486                                                                                                                                                                                        playing pet society\n",
      "19383                                              : I saw US Postal was hiring, but once I was done filling out the pre-application thingy it didn't show_NEG me_NEG jobs_NEG open_NEG in_NEG the_NEG area._NEG\n",
      "7300                                                                                                        Got the keys to my new flat - gorgeous weather for weekend - and i'm spending it &quot;PACKING&quot;\n",
      "12279                                                                                                                                                 hates not having_NEG money_NEG roll_NEG on_NEG payday!_NEG\n",
      "16406                                                                                                                                      i don't wanna_NEG go_NEG back_NEG to_NEG school_NEG on_NEG monday_NEG\n",
      "5342     I have had it with job hunting. I try all day and nothing works_NEG I_NEG bet_NEG I_NEG couldn't_NEG even_NEG work_NEG at_NEG the_NEG strip_NEG club_NEG because_NEG of_NEG my_NEG cider_NEG belly!_NEG\n",
      "17119                                                                                                                                                     ahh i wish you guys would come to a hot topic near me.\n",
      "8836                                                                                         not funny_NEG he_NEG profiled_NEG my_NEG ass._NEG Like_NEG wtf?_NEG I'm_NEG still_NEG kinda_NEG heated._NEG Ugh_NEG\n",
      "17506                                                                                                                     awe.. that sucks and I can't... we're_NEG trying_NEG raffis'_NEG birthday_NEG &lt;_NEG\n",
      "9355                                                                                         Oh, fuck me. I've just returned from the Supermarket Of Doom to find that I have nothing to_NEG drink_NEG here._NEG\n",
      "18278                                                                                                                    Days left until freedom. I really just want to get through this weekend. I hate essays.\n",
      "21211                                                                                                                                                                               dw you never will_NEG xx_NEG\n",
      "14571                                                                                                   aw poor u DON'T let her get u just ignore her n keep ur head held high she iz just immature lil girl lol\n",
      "26521                                                                                      y r we giving up on people? I actually thought that way for a while too before I found someone who is very intriguing\n",
      "4014                                                                                                                                     suffering benadryl hangover this morning and a killer headache.... ugh!\n",
      "1366                                                                                                         I would be playing my old rogue but a friend took the account and could not get_NEG it_NEG back_NEG\n",
      "7226                                                                                                                                                      ahh I hate being sick Watching atonement! and sleeping\n",
      "17955                                                                               No FTP/Browser on the Mac I may visit an old Mac Lab or Sneakernet with ZIPs to Kinkos. Anyone with Fetch on a Floppy? DM me\n",
      "1251                                                                                                                                                             says BAD TRIP! (angry) http://plurk.com/p/wxshi\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 7 love\n",
      "28441                                                                                    hi everyone, hoping all of you have a good week\n",
      "25592                                                                                        new album is truly genius, so happy with it\n",
      "20285                                                                     Hello!! sounds very good, you can count on me, I follow you!!!\n",
      "14119                                   Wow, I've officially lost all faith in Britain, looks like our wishes weren't met,_NEG sadly_NEG\n",
      "28050                                                                                      Great, social network sites are still growing\n",
      "6273                                                                              hey love whats up! my voice is shot whats new with you\n",
      "22795                                                                                                  awww cuuuute Newborns are so fun!\n",
      "3191                                                                                         You poor thing Hang in there. -xxx- luf joe\n",
      "2411                                                                                        what a bummer that tomorrow is friday again!\n",
      "25650                                        Had an awesome weekend and an awesome turn out to my rummage sales on friday and saturday!!\n",
      "1978     Ok so I did shed a few tears watching the preview for next weeks Medium. I'm so scared. I'm so addicted to this show. I love it\n",
      "25236                                                                                      hey! YAY! thanks! wow ur page is awesome!!!!!\n",
      "23066                                                     ? I had great time in Boston. Thanks to my baby girl. http://plurk.com/p/rplmy\n",
      "19477                                           ...thanks for the shout out...you might be right about the starving thing.... little lol\n",
      "23655                                                                                                            I'M A CELEBRITY TOOOOO!\n",
      "7380                                                                              ? THANK YOU sana matanggap ako http://plurk.com/p/xyts\n",
      "19395                                                Trying to reorganize plans for tonight uggg Hopefully it will still be lots 'o fun!\n",
      "13374                                                                                                                     awwwwww *hugs*\n",
      "26914                                                     Looking at my quince pics, ahh good memories.... To be young again.... Lol #fb\n",
      "28555                                                                                Watching HG-TV....and a cute carpenter guy woo hoo!\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 8 neutral\n",
      "12573                                                                                                                                                                               Must head back to the office\n",
      "1476                                                                                                                                                                                              crash in Qmbol\n",
      "5120                                                                                                                                                                                    only more days of minnie\n",
      "20371    not sure_NEG I_NEG like_NEG this_NEG way_NEG to_NEG learn_NEG a_NEG new_NEG language_NEG I_NEG prefer_NEG to_NEG be_NEG &quot;on_NEG location&quot;,_NEG so_NEG I_NEG can_NEG practice,_NEG ask_NEG ...\n",
      "4984                                                                                                                        i love how nice the weather is today and i am camping tonight! oh and i hate my hair\n",
      "21382                                                                                                                                    I think that's the Muji stabilo. Because she was eyeing mine last week.\n",
      "537                                                                                                                                                                       still!! give your computer a break omg\n",
      "1292                                                                                                                                                        need a camera blower.. my camera censor is dirteeh..\n",
      "7842                                                                                                                                                                     i'm trying to figure that out right now\n",
      "1759                                                                                                                                                         excited for YSJ Summer Ball - I wish we had one too\n",
      "12582                                                                               Getting ready to ship a care package to the daughter. She's not coming_NEG home_NEG this_NEG summer_NEG from_NEG college_NEG\n",
      "3811                                                                                                                       is missing out on the sunshine and trying to stay awake after having just hours sleep\n",
      "12765                                                                                                  NCAA Baseball Road Omaha: South Carolina just hit a-run homerun. Dagger my heart. Mason - South Carolina.\n",
      "12866                                                                                                                                                                Tonight is the last Jay Leno late nigt show\n",
      "1906                                                                                                                                           we just missd each otha again! I was at disney all day YESTERday!\n",
      "7962                                                                                                Whew! Moving commercial-sized freezer and cooler a lot more work than I expected. Missing the HTC roundtable\n",
      "22920                                                                                                                                                     Looking forward to android being pushed to the G then?\n",
      "15421                                                                                                                                  is not getting_NEG her_NEG posts_NEG posted_NEG to_NEG the_NEG topics_NEG\n",
      "15451                                                                              I TRIED TO PUT A IRON ON , ON MY BOOK BAG AND I BURNT MY BAG WITH THE IRON LOL.. BUZZ KEEP MAKING FUN OF ME ... (BASTARD) LOL\n",
      "22073                                                                                              think to start off with but a house that can fit - or we may go the whole hog and get... not sure_NEG yet_NEG\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 9 relief\n",
      "28279                                                                                                     That's the good part about it. YOU DON'T HAVE TO KNOW ANYONE!\n",
      "1684                                                                                                                       on that note - i do not feel_NEG missed._NEG\n",
      "8241                                                                                                                                                       work all day\n",
      "19976                                                            aww i'm sorry glad mommy took care of you. erin is in for some fun if there's a bug on you in colorado\n",
      "23228                                                                                                        it actually is ;) According to all the retweets, at least!\n",
      "12618                                                                                                                          not doing_NEG relay_NEG oh_NEG well._NEG\n",
      "2164                                                                                 Happy belated Birthday to Billy!! I forgot to say that on his bday. I feel aweful!\n",
      "10959                                                                             My replacement iron ring arrived. It's shiny. And a bit more jagged than the original\n",
      "18692                         i was so bored i decided to iron all my baju sklh. thn i realized i hate doing tht. so all i did was iron a sleeve HAHAHA. im off to schl\n",
      "27898    I'm grateful that my kids also don't like_NEG them,_NEG lol._NEG Textbooks_NEG are_NEG a_NEG tool,_NEG not_NEG the_NEG sole_NEG means_NEG of_NEG education_NEG\n",
      "1141                                                                                                                                                ME! I wanted to go.\n",
      "23468                  I've been quite lucky this weekend... Slight headache here n there, but nothing incapacitating_NEG yay_NEG me!_NEG Poor_NEG Carol_NEG tho..._NEG\n",
      "19331                                                                                             hey they do have that but these never bothered_NEG me_NEG before._NEG\n",
      "3629                                                                                                                   Roommate is sssnoring :/ And my throat is so dry\n",
      "1196                                                                                                                                          should updatd her twitter\n",
      "24972                                                                                                                      getting ready for my first day at my new job\n",
      "28838                                                                                                                     phew! made it thru the return of babysitting!\n",
      "1024                                                                                        Off work, trying to relax for about mins before I've gotta go back to sleep\n",
      "20514                                                                                                                      Ah, the bank holiday shift at work. What fun\n",
      "25815                                                                                 Drinking tea and eating choc chip cookies. Going to head to sleep soon! Night all\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 10 sadness\n",
      "8856                                                                  I've got sunburn on my arm In better news, my new Guitar Hero: Metallica game came and I beyond happy about that.\n",
      "13012                                                                             Damn Frat - that's too bad... Should be a good show (at least I'm hoping so) esp. since it's in BK...\n",
      "6793                                                                 and he's not even_NEG fat!!!!_NEG Huh,_NEG He's_NEG just_NEG friggin_NEG huge!_NEG I_NEG have_NEG a_NEG freak._NEG\n",
      "13638                                                                                                   bad mood and i dont feel_NEG good._NEG too_NEG bad_NEG no_NEG one_NEG cares_NEG\n",
      "7818                                                                                                                                              Why is it soooo cold &amp; ugly out??\n",
      "6141                                                                                                                     lucky girl!!! I work all day tomorrow! and maybe even Monday!!\n",
      "9912                                                                                      At home sick.. On a friday...studying is all im doing at this point.. My weekend is so ruined\n",
      "343                                                                                                                                   Sad that Christian Lacroix had to file bankruptcy\n",
      "27266                                                                                                                                               sooo long twitters! I'm off to Cuba\n",
      "22964                                                                           cï¿½m on anh ko the chiu no~i noi nhï¿½ Tifa roi :-D, thang Cloud danh dam gi mac ke no :&quot;&gt;_NEG\n",
      "14701                                                                                                                      It'spm on a Friday night and I'm going to bed. How pathetic.\n",
      "13161                                                                                                                                                                my head is hurting\n",
      "10099                                                SHIT I lost my Star Trek ring! Starfleet Academy class ring w/ Golden Gate Bridge on it. Got it as high school graduation present.\n",
      "16791                                                       hoping it'll go away... I mean I get all teary at the drop of a hat anyway, but it's been truly awful lately - full out sad\n",
      "13818                                                     Aw, Kaelah I feel so bad for you. This sounds serious? Please get better soon. I admire you for still working hard and stuff.\n",
      "7920                                                                                                                                          they won't guys_NEG are_NEG retarded!_NEG\n",
      "11728    (cont.) Small children are not puppies._NEG And_NEG cleche_NEG sarcasm_NEG is_NEG so_NEG annoying._NEG Bcreative,_NEG but_NEG then_NEG again,_NEG that's_NEG too_NEG harrd_NEG\n",
      "4013               sadly no, sitting inside as mobile signal won't work_NEG in_NEG the_NEG garden_NEG I'll_NEG be_NEG opening_NEG the_NEG wine_NEG at_NEG bang_NEG onpm_NEG though!_NEG\n",
      "8322                                                                                                hillsong tom. night, and dad's birthday! i wish i could see him on his bday though.\n",
      "14878                                                                                                           i have officially hit the wall, totally nonfunctionalproductive at work\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 11 surprise\n",
      "29621                                                                                                                                                                                     it's Mothers Day today\n",
      "12494                                                                                                                 wondering if my local Borders is going to make it. Lots of bare shelves... It makes me sad\n",
      "2684                                                                                                              Not ah huge fan of getting up in the middle of the night to change peed sheets and underpants.\n",
      "456                                                                                                                                 Not really sleepy ...bored is the right word ... again not much_NEG work_NEG\n",
      "1603                                                                            Getting rather annoyed at my notebook. I know it's old and has got wrinkles but it's never been_NEG this_NEG slow_NEG before_NEG\n",
      "18388                                                                                      ilooked in my phone book and ur name was the first to show and i was like i got ti-ti number but it was just ur email\n",
      "26825                                                                                                                                    Excited about having an empty apartment to ourselves for a little while\n",
      "5522                                                              u never told_NEG me_NEG abt_NEG ur_NEG date_NEG ..._NEG who_NEG is_NEG the_NEG lucky_NEG guy_NEG im_NEG so_NEG out_NEG of_NEG the_NEG loop_NEG\n",
      "5231                                                                                                                                                             Sometimes I wish I had my own Prototype mentor.\n",
      "6295     On the way back to dublin Omg didnt hit_NEG the_NEG bed_NEG until_NEG so_NEG i_NEG am_NEG so_NEG sleepy_NEG but_NEG once_NEG again_NEG on_NEG the_NEG road_NEG back_NEG to_NEG good_NEG ole_NEG dubl...\n",
      "4987                                                                                        is waiting for the estate agent to do valuation. oh joy. *sigh* i need to be in the funhouse pink baby come back!!!!\n",
      "15888                                                                                                                       OMG at that Almost in our's comment!! Same Bday as Joe here...But I turn..OMG....lol\n",
      "27765                                                                                                                                                                                             oh nice going!\n",
      "16249                                                                                                                                                          Yo nate, what's going on with Morgie? Is she ok??\n",
      "18268                                                                                                              Ecaytrade people who said you'd come by stuff at:.where are you ? Bugs me when people no-show\n",
      "6407                                                                                                                                        http://twitpic.com/sls - and I just saw this monster dog in the park\n",
      "21915                                                                                                                                           Oh, wow, you're fast How's life going ? It's been months ya ? XD\n",
      "23313                                                                                                                                                                                       Ba-dum-tish! You win\n",
      "7105                                                                          yes! sober HAHAHA tanghaling tapat dude! haha WILD. i don't knowwww_NEG plan_NEG plan_NEG before_NEG you_NEG go_NEG to_NEG US!_NEG\n",
      "10594                                                                                        i wish that mcfly dream was real aha, i want tom to write in my action plannner haaa, it would be awesome though ;D\n",
      "Name: content, dtype: object\n",
      "-------------------------------------------------\n",
      "False Negatives for class: 12 worry\n",
      "17945                                                                             Well, it's very hot out. And i want to listen to lines,vines,and trying times!!\n",
      "4461                                                                                                                                                   That sucks\n",
      "13444    cool that you liked germany and the awards! i saw you on TV cause i couldn't come_NEG to_NEG the_NEG comet_NEG and_NEG see_NEG you_NEG live_NEG xoxo_NEG\n",
      "26339                                                                                                      Listening to my favourite song... ALLAH KE BANDE HASDE\n",
      "5193                                            You must be doing different poetry to me. All we get is Catullus, some Ovid and and an extract from the Aeneid. x\n",
      "9186                                       Sitting in boring ass litterature listening to jack Johnson missing the gf soooooooooooooooooooooooooooooooooooo much.\n",
      "10030                                                                                                                               I had to find out via twitter\n",
      "11576                                                         i used to have an ozzy osbourne pillow with his face on it. my mom threw it out. i miss that thing.\n",
      "11084                                                                               lolz dude I have to stop it got too personal my homegirl my be on twitter lol\n",
      "16003                         yes - it has put a damper on us &quot;getting to know&quot; Georgetown! Instead he is watching tv and I am catching up on invoices.\n",
      "9300                                                                                                                                                not funny_NEG\n",
      "10834                                                                  is sad that she is not seeing_NEG Basshunter_NEG at_NEG Metroplex_NEG this_NEG weekend_NEG\n",
      "26462                                                                                                                                                     since '\n",
      "1602                                                                                                                  @ Pretty_Mess you missed all the free shots\n",
      "16336                                                      Better than what I did to my MacBook keyboard yesterday! (Spilled a whole cup of hot chocolate on it.)\n",
      "5739                                                                                                      very excited, although her train is going to be delayed\n",
      "17370                                                                                                                 Trying to figure out how this works ... BOO\n",
      "22931                                                                                                                     yeah that will keep my mid section down\n",
      "18145                                               Just finished bowling with my family. It's definately not the_NEG same_NEG as_NEG with_NEG my_NEG friends_NEG\n",
      "10562                                                                                      and I SIT HERE all on my own doing nowt hmmpfff lol..have a good night\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pred_class_name = list(label_encoder.classes_)\n",
    "\n",
    "for pred_class_num in range(0,len(pred_class_name)):\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"False Negatives for class: {} {}\".format(pred_class_num, pred_class_name[pred_class_num]))\n",
    "    fn_class = X_test[(results_df.y_test == pred_class_num) & (results_df.y_pred != pred_class_num)]\n",
    "    print(fn_class.head(20))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering from Baseline DataFrame\n",
    "\n",
    "At this point we have a baseline data frame and we can start to look at feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Functions used to create different features from the text.\n",
    "def count_username_mentions(value):\n",
    "    return len(re.findall(r\"@[^\\s]+[\\s]?\", value))\n",
    "\n",
    "def count_ellipsis(value):\n",
    "    return len(re.findall(r\"\\.\\s?\\.\\s?\\.\", value))\n",
    "\n",
    "def count_hashtags(value):\n",
    "    return len(re.findall(r\"3[^\\s]+[\\s]?\", value))\n",
    "\n",
    "def count_exclamation_points(value):\n",
    "    groups = re.findall(r\"\\w+(!+)\", value)\n",
    "    return sum([len(exclamation_string) for exclamation_string in groups])\n",
    "\n",
    "def count_question_marks(value):\n",
    "    groups = re.findall(r\"[\\w+!](\\?+)\", value)\n",
    "    return sum([len(exclamation_string) for exclamation_string in groups])\n",
    "\n",
    "def is_boredom(y):\n",
    "    if 'bored' in y.lower() or 'boring' in y.lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_features(df):\n",
    "    df['number_of_mentions'] = df.content.apply(count_username_mentions)\n",
    "    df['number_of_ellipsis'] = df.content.apply(count_ellipsis)\n",
    "    df['number_of_exclamations'] = df.content.apply(count_exclamation_points)\n",
    "    df['number_of_hashtabs'] = df.content.apply(count_hashtags)\n",
    "    df['number_of_question'] = df.content.apply(count_question_marks)\n",
    "    df['is_boredom'] = df.content.apply(is_boredom)\n",
    "    df['content_len'] = df.content.apply(len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment  \\\n",
       "0       empty   \n",
       "1     sadness   \n",
       "2     sadness   \n",
       "3  enthusiasm   \n",
       "4     neutral   \n",
       "\n",
       "                                                                                        content  \n",
       "0  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[  \n",
       "1                                  Layin n bed with a headache  ughhhh...waitin on your call...  \n",
       "2                                                           Funeral ceremony...gloomy friday...  \n",
       "3                                                          wants to hang out with friends SOON!  \n",
       "4        @dannycastillo We want to trade with someone who has Houston tickets, but no one will.  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../data/kaggle/sa-emotions/train_data.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_ellipsis</th>\n",
       "      <th>number_of_exclamations</th>\n",
       "      <th>number_of_hashtabs</th>\n",
       "      <th>number_of_question</th>\n",
       "      <th>is_boredom</th>\n",
       "      <th>content_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment  \\\n",
       "0       empty   \n",
       "1     sadness   \n",
       "2     sadness   \n",
       "3  enthusiasm   \n",
       "4     neutral   \n",
       "\n",
       "                                                                                        content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                                  Layin n bed with a headache  ughhhh...waitin on your call...   \n",
       "2                                                           Funeral ceremony...gloomy friday...   \n",
       "3                                                          wants to hang out with friends SOON!   \n",
       "4        @dannycastillo We want to trade with someone who has Houston tickets, but no one will.   \n",
       "\n",
       "   number_of_mentions  number_of_ellipsis  number_of_exclamations  \\\n",
       "0                   1                   0                       0   \n",
       "1                   0                   2                       0   \n",
       "2                   0                   2                       0   \n",
       "3                   0                   0                       1   \n",
       "4                   1                   0                       0   \n",
       "\n",
       "   number_of_hashtabs  number_of_question  is_boredom  content_len  \n",
       "0                   0                   0           0           92  \n",
       "1                   0                   0           0           60  \n",
       "2                   0                   0           0           35  \n",
       "3                   0                   0           0           36  \n",
       "4                   0                   0           0           86  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_features(raw_data)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10e2d14a8>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEcCAYAAAAoSqjDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dd49f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a boxplot showing the sentiment versus the content_len and see if there is any noticable\n",
    "# relationship between content length and the emotion\n",
    "# box plot of number ingredients for each cuisine\n",
    "raw_data.boxplot('content_len', by='sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def liu_hu_lexicon(sentence, verbose=False):\n",
    "    \"\"\"\n",
    "    Basic example of sentiment classification using Liu and Hu opinion lexicon.\n",
    "    This function simply counts the number of positive, negative and neutral words\n",
    "    in the sentence and classifies it depending on which polarity is more represented.\n",
    "    Words that do not appear in the lexicon are considered as neutral.\n",
    "\n",
    "    :param sentence: a sentence whose polarity has to be classified.\n",
    "    :param plot: if True, plot a visual representation of the sentence polarity.\n",
    "    :return array of integers: 1 = positive, 0 = neutral, -1 = negative\n",
    "    \"\"\"\n",
    "    from nltk.corpus import opinion_lexicon\n",
    "    from nltk.tokenize import treebank\n",
    "\n",
    "    tokenizer = treebank.TreebankWordTokenizer()\n",
    "    pos_words = 0\n",
    "    neg_words = 0\n",
    "    tokenized_sent = [word.lower() for word in tokenizer.tokenize(sentence)]\n",
    "\n",
    "    x = list(range(len(tokenized_sent))) # x axis for the plot\n",
    "    y = []\n",
    "\n",
    "    for word in tokenized_sent:\n",
    "        if word in opinion_lexicon.positive():\n",
    "            pos_words += 1\n",
    "            y.append(1) # positive\n",
    "        elif word in opinion_lexicon.negative():\n",
    "            neg_words += 1\n",
    "            y.append(-1) # negative\n",
    "        else:\n",
    "            y.append(0) # neutral\n",
    "\n",
    "    y_sum = sum(y) \n",
    "    if y_sum > 0:\n",
    "        disposition = 1\n",
    "    elif y_sum < 0:\n",
    "        disposition = -1\n",
    "    else:\n",
    "        disposition = 0\n",
    "    \n",
    "    if verbose:\n",
    "        if disposition == 1:\n",
    "            print('Positive: {}'.format(sentence))\n",
    "        elif disposition == -1:\n",
    "            print('Negative: {}'.format(sentence))\n",
    "        else:\n",
    "            print('Neutral: {}'.format(sentence))\n",
    "\n",
    "    return disposition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES A VERY VERY LONG TIME\n",
    "#liu_hu_lexicon_series = training_data.content.apply(liu_hu_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "anger         0.724490\n",
      "boredom       0.350318\n",
      "empty         0.270106\n",
      "enthusiasm    0.693487\n",
      "fun           0.718750\n",
      "happiness     0.807100\n",
      "hate          0.619208\n",
      "love          0.658607\n",
      "neutral       0.285804\n",
      "relief        0.491675\n",
      "sadness       0.411350\n",
      "surprise      0.542467\n",
      "worry         0.408180\n",
      "Name: number_of_exclamations, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped = raw_data.groupby('sentiment')\n",
    "print(grouped['number_of_exclamations'].agg(np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "anger         0.438776\n",
      "boredom       0.254777\n",
      "empty         0.493171\n",
      "enthusiasm    0.507663\n",
      "fun           0.607537\n",
      "happiness     0.531815\n",
      "hate          0.364785\n",
      "love          0.575435\n",
      "neutral       0.547003\n",
      "relief        0.460333\n",
      "sadness       0.415079\n",
      "surprise      0.539988\n",
      "worry         0.439796\n",
      "Name: number_of_mentions, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "grouped = raw_data.groupby('sentiment')\n",
    "print(grouped['number_of_mentions'].agg(np.mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x118249278>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEcCAYAAAAvJLSTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116e7c080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data.boxplot('number_of_mentions', by='sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out the new Training DataFrame with the new feature columns.\n",
    "\n",
    "This training data set will be used as the input when working through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write out the new dataframe\n",
    "\n",
    "raw_data.to_csv('../data/kaggle/sa-emotions/train_data_with_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 9)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready for final Modeling\n",
    "\n",
    "We now have a training data set with the original content PLUS additional feature columns.\n",
    "\n",
    "Now we can read in the training data, and create the necessary preprocessing pipelines and feature unions to run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentimentNumberTransformer(TransformerMixin):\n",
    "\n",
    "    def __init__(self, unique_labels):\n",
    "        # encode the sentiment outcomes as a number using the LabelEncoder\n",
    "        # would like to create a column, e.g. sentiment_num, which is a numeric representation of the sentiment.\n",
    "        # this will have to also be applied to any test data.\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        # fit the label encoder with the unique set of sentiments in the training data.\n",
    "        self.label_encoder.fit(unique_labels)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: DataFrame\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        X['sentiment_num'] = X.sentiment.apply(lambda x: self.label_encoder.transform([x])[0])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment  \\\n",
       "0       empty   \n",
       "1     sadness   \n",
       "2     sadness   \n",
       "3  enthusiasm   \n",
       "4     neutral   \n",
       "\n",
       "                                                                                        content  \n",
       "0  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[  \n",
       "1                                  Layin n bed with a headache  ughhhh...waitin on your call...  \n",
       "2                                                           Funeral ceremony...gloomy friday...  \n",
       "3                                                          wants to hang out with friends SOON!  \n",
       "4        @dannycastillo We want to trade with someone who has Houston tickets, but no one will.  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the training data\n",
    "training_data = pd.read_csv('../data/kaggle/sa-emotions/train_data.csv')\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the data, setup the function transformers, add the features to the training data.\n",
    "\"\"\"\n",
    "\n",
    "# -----------------  Function Transformers ----------------\n",
    "def get_features_df(df):\n",
    "    return df.loc[:, ['number_of_mentions', 'number_of_ellipsis', 'number_of_exclamations', 'number_of_hashtabs', 'number_of_question', 'is_boredom', 'content_len']]\n",
    "\n",
    "def get_sentiment_content(df):\n",
    "    return df.content.copy()\n",
    "\n",
    "def get_sentiment_content_negation(df):\n",
    "    return df.content_negation.copy()\n",
    "\n",
    "def get_sentiment_content_preprocess_negation(df):\n",
    "    return df.content_preprocessed_negation\n",
    "\n",
    "\n",
    "# create a function transformer to just extract the feature columns\n",
    "get_features_transformer = FunctionTransformer(get_features_df, validate=False)\n",
    "# usage: get_features_transformer.transform(training_data_with_features).head()\n",
    "\n",
    "# create a function transformer to return the sentiment content so it can be used in pipeline/union\n",
    "get_sentiment_content_transformer = FunctionTransformer(get_sentiment_content, validate=False)\n",
    "\n",
    "get_sentiment_content_negation_transformer = FunctionTransformer(get_sentiment_content_negation, validate=False)\n",
    "\n",
    "get_sentiment_content_preprocess_negation_transformer = FunctionTransformer(get_sentiment_content_preprocess_negation, validate=False)\n",
    "\n",
    "# -----------------  End Function Transformers ----------------\n",
    "\n",
    "def preprocess_data_set(input_data_set):\n",
    "\n",
    "\n",
    "    # encode the sentiment outcomes as a number using the LabelEncoder\n",
    "    # would like to create a column, e.g. sentiment_num, which is a numeric representation of the sentiment.\n",
    "    # this will have to also be applied to any test data.\n",
    "    label_encoder = LabelEncoder()\n",
    "    # fit the label encoder with the unique set of sentiments in the training data.\n",
    "    label_encoder.fit(input_data_set.sentiment.unique())\n",
    "    # print out what classes were discovered\n",
    "    #print(list(label_encoder.classes_))\n",
    "    # add the sentiment_num column\n",
    "    input_data_set['sentiment_num'] = input_data_set.sentiment.apply(lambda x: label_encoder.transform([x])[0])\n",
    "\n",
    "    # Create a pipeline with the transformers we are keeping, and see the overall improvement.\n",
    "    preprocessor_pipeline = make_pipeline(get_sentiment_content_transformer, RemoveNumbersTransformer(), RemoveUsernameTransformer())\n",
    "    preprocessed_training_data_content = preprocessor_pipeline.transform(input_data_set)\n",
    "    input_data_set['content_preprocessed'] = preprocessed_training_data_content\n",
    "    input_data_set['content_preprocessed_negation'] = input_data_set.content_preprocessed.apply(mark_negation_sentence)\n",
    "\n",
    "    make_features(input_data_set)\n",
    "\n",
    "    #training_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocess_data_set(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment_num</th>\n",
       "      <th>content_preprocessed</th>\n",
       "      <th>content_preprocessed_negation</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_ellipsis</th>\n",
       "      <th>number_of_exclamations</th>\n",
       "      <th>number_of_hashtabs</th>\n",
       "      <th>number_of_question</th>\n",
       "      <th>is_boredom</th>\n",
       "      <th>content_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>2</td>\n",
       "      <td>i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>i know i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "      <td>10</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "      <td>Layin n bed with a headache ughhhh...waitin on your call...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>10</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>3</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "      <td>8</td>\n",
       "      <td>We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "      <td>We want to trade with someone who has Houston tickets, but no one_NEG will._NEG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment  \\\n",
       "0       empty   \n",
       "1     sadness   \n",
       "2     sadness   \n",
       "3  enthusiasm   \n",
       "4     neutral   \n",
       "\n",
       "                                                                                        content  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                                  Layin n bed with a headache  ughhhh...waitin on your call...   \n",
       "2                                                           Funeral ceremony...gloomy friday...   \n",
       "3                                                          wants to hang out with friends SOON!   \n",
       "4        @dannycastillo We want to trade with someone who has Houston tickets, but no one will.   \n",
       "\n",
       "   sentiment_num  \\\n",
       "0              2   \n",
       "1             10   \n",
       "2             10   \n",
       "3              3   \n",
       "4              8   \n",
       "\n",
       "                                                               content_preprocessed  \\\n",
       "0  i know  i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                      Layin n bed with a headache  ughhhh...waitin on your call...   \n",
       "2                                               Funeral ceremony...gloomy friday...   \n",
       "3                                              wants to hang out with friends SOON!   \n",
       "4           We want to trade with someone who has Houston tickets, but no one will.   \n",
       "\n",
       "                                                     content_preprocessed_negation  \\\n",
       "0  i know i was listenin to bad habit earlier and i started freakin at his part =[   \n",
       "1                      Layin n bed with a headache ughhhh...waitin on your call...   \n",
       "2                                              Funeral ceremony...gloomy friday...   \n",
       "3                                             wants to hang out with friends SOON!   \n",
       "4  We want to trade with someone who has Houston tickets, but no one_NEG will._NEG   \n",
       "\n",
       "   number_of_mentions  number_of_ellipsis  number_of_exclamations  \\\n",
       "0                   1                   0                       0   \n",
       "1                   0                   2                       0   \n",
       "2                   0                   2                       0   \n",
       "3                   0                   0                       1   \n",
       "4                   1                   0                       0   \n",
       "\n",
       "   number_of_hashtabs  number_of_question  is_boredom  content_len  \n",
       "0                   0                   0           0           92  \n",
       "1                   0                   0           0           60  \n",
       "2                   0                   0           0           35  \n",
       "3                   0                   0           0           36  \n",
       "4                   0                   0           0           86  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32503805215779058"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create stemmer and vectorizer\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "stemmed_tfidf_vectorizer = StemmedTfidfVectorizer(stemmer=stemmer, min_df=5, max_df=0.8, ngram_range=(1,4), stop_words='english', sublinear_tf=True)\n",
    "\n",
    "\n",
    "union = make_union(make_pipeline(get_sentiment_content_preprocess_negation_transformer, stemmed_tfidf_vectorizer),\n",
    "                  get_features_transformer)\n",
    "\n",
    "# check to the resulting document term matrix\n",
    "#X_dtm = union.fit_transform(training_data)\n",
    "#X_dtm.shape\n",
    "\n",
    "\n",
    "y = training_data.sentiment_num\n",
    "\n",
    "\n",
    "# create LogisticRegression Model\n",
    "# 0.3250\n",
    "model = LogisticRegression(C=0.1)\n",
    "\n",
    "# 0.307\n",
    "#model = MultinomialNB()\n",
    "\n",
    "model_pipeline = make_pipeline(union, model)\n",
    "cross_val_score(model_pipeline, training_data, y, cv=5, scoring='accuracy').mean()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
